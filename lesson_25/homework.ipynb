{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55d092b",
   "metadata": {},
   "source": [
    "## Hometask \n",
    "\n",
    "1) Classify the signs (fingers)  dataset \n",
    "\n",
    "2) Try to change the number of hidden layer \n",
    "\n",
    "3) Change the activation to tanh or sigmoid and see what happens\n",
    "\n",
    "4) Change the dropout ratio and check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc4f4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ba7bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape= (1080, 64, 64, 3)\n",
      "train_labels.shape= (1, 1080)\n",
      "test_data.shape= (120, 64, 64, 3)\n",
      "test_labels.shape= (1, 120)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    fn = 'supplementary_data/train_signs.h5'\n",
    "    train_dataset = h5py.File(fn, \"r\")\n",
    "    X_train = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    Y_train = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    fn = 'supplementary_data/test_signs.h5'\n",
    "    test_dataset =  h5py.File(fn, \"r\")\n",
    "    X_test = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    Y_test = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    Y_train = Y_train.reshape((1, Y_train.shape[0]))\n",
    "    Y_test = Y_test.reshape((1, Y_test.shape[0]))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test, classes\n",
    "\n",
    "train_data, train_labels, test_data, test_labels, classes = load_dataset()\n",
    "\n",
    "print ('train_data.shape=', train_data.shape)\n",
    "print ('train_labels.shape=',  train_labels.shape)\n",
    "print ('test_data.shape=', test_data.shape)\n",
    "print ('test_labels.shape=', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75fff500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12288 (1080, 12288) (120, 12288)\n",
      "Number of classes:  6\n",
      "Original label [0] :  [5 0 2 ... 2 4 5]\n",
      "After conversion to categorical ( one-hot ) :  [0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#preprocess the data\n",
    "X_train = train_data.astype('float32')\n",
    "X_test = test_data.astype('float32')\n",
    "\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# Change from matrix to array of dimension 64x64 to array of dimension 12288\n",
    "dimData = np.prod(X_train.shape[1:])\n",
    "X_train = X_train.reshape(X_train.shape[0], dimData) # think could be just -1 \n",
    "X_test = X_test.reshape(X_test.shape[0], dimData)\n",
    "\n",
    "Y_train_one_hot = to_categorical(train_labels.flatten())\n",
    "Y_test_one_hot = to_categorical(test_labels.flatten())\n",
    "\n",
    "print(dimData, X_train.shape, X_test.shape)\n",
    "print('Number of classes: ', len(classes))\n",
    "print('Original label [0] : ', train_labels[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', Y_train_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409c7507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dc78bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, activation='relu', dropout_rate=0.3, hidden_units=[512, 256], num_classes=6):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = []\n",
    "        for units in hidden_units:\n",
    "            self.hidden_layers.append(Dense(units, activation=activation))\n",
    "            self.hidden_layers.append(Dropout(dropout_rate))\n",
    "        self.output_layer = Dense(num_classes, activation='softmax')\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6a01ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropouts = [0.1, 0.3, 0.5, 0.7]\n",
    "activations = ['relu', 'sigmoid', 'tanh']\n",
    "hidden_units_list = [[512, 256], [256, 128], [128, 64], [512, 256, 128], [128, 256, 128]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58b2a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Available devices: {tf.config.list_physical_devices()}\")\n",
    "device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79711cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with dropout=0.1, activation=relu, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.1625 - loss: 1.7940 - val_accuracy: 0.1667 - val_loss: 1.7845\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1959 - loss: 1.7822 - val_accuracy: 0.1667 - val_loss: 1.7650\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2180 - loss: 1.7673 - val_accuracy: 0.3583 - val_loss: 1.7191\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2996 - loss: 1.7161 - val_accuracy: 0.3583 - val_loss: 1.6498\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.3065 - loss: 1.6469 - val_accuracy: 0.3000 - val_loss: 1.5962\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.3567 - loss: 1.5807 - val_accuracy: 0.2917 - val_loss: 1.5109\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.4149 - loss: 1.4914 - val_accuracy: 0.4667 - val_loss: 1.3516\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.4706 - loss: 1.3709 - val_accuracy: 0.5333 - val_loss: 1.3105\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.4893 - loss: 1.3009 - val_accuracy: 0.5000 - val_loss: 1.2097\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5711 - loss: 1.2142 - val_accuracy: 0.5583 - val_loss: 1.1512\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5501 - loss: 1.1774 - val_accuracy: 0.4750 - val_loss: 1.1928\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.5491 - loss: 1.1453 - val_accuracy: 0.5083 - val_loss: 1.1407\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5879 - loss: 1.1127 - val_accuracy: 0.5000 - val_loss: 1.1760\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.5694 - loss: 1.1382 - val_accuracy: 0.5917 - val_loss: 1.0066\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.6372 - loss: 0.9924 - val_accuracy: 0.5417 - val_loss: 1.0970\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.6331 - loss: 0.9788 - val_accuracy: 0.6000 - val_loss: 0.9895\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.6406 - loss: 0.9586 - val_accuracy: 0.6000 - val_loss: 1.0050\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.6428 - loss: 0.9580 - val_accuracy: 0.5750 - val_loss: 0.9655\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.6701 - loss: 0.8760 - val_accuracy: 0.5917 - val_loss: 0.9950\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.6179 - loss: 0.9193 - val_accuracy: 0.6417 - val_loss: 0.9354\n",
      "Validation accuracy: 0.6417\n",
      "\n",
      "Training model with dropout=0.1, activation=relu, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.1566 - loss: 1.7955 - val_accuracy: 0.1667 - val_loss: 1.7862\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1658 - loss: 1.7854 - val_accuracy: 0.2667 - val_loss: 1.7776\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2265 - loss: 1.7730 - val_accuracy: 0.3250 - val_loss: 1.7501\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2786 - loss: 1.7498 - val_accuracy: 0.2917 - val_loss: 1.7097\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2674 - loss: 1.7098 - val_accuracy: 0.3750 - val_loss: 1.6653\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3744 - loss: 1.6289 - val_accuracy: 0.4917 - val_loss: 1.5487\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3980 - loss: 1.5358 - val_accuracy: 0.4917 - val_loss: 1.4619\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4306 - loss: 1.4567 - val_accuracy: 0.5000 - val_loss: 1.3638\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4631 - loss: 1.3871 - val_accuracy: 0.5000 - val_loss: 1.3147\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4881 - loss: 1.3448 - val_accuracy: 0.4833 - val_loss: 1.3239\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5379 - loss: 1.2528 - val_accuracy: 0.5333 - val_loss: 1.2051\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5467 - loss: 1.2294 - val_accuracy: 0.5750 - val_loss: 1.1710\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5626 - loss: 1.1469 - val_accuracy: 0.6167 - val_loss: 1.1144\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5940 - loss: 1.1525 - val_accuracy: 0.5000 - val_loss: 1.2459\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5653 - loss: 1.0976 - val_accuracy: 0.5583 - val_loss: 1.1400\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5750 - loss: 1.0921 - val_accuracy: 0.5583 - val_loss: 1.0506\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6280 - loss: 0.9900 - val_accuracy: 0.5417 - val_loss: 1.1668\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5811 - loss: 1.0765 - val_accuracy: 0.6000 - val_loss: 1.0190\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6084 - loss: 1.0070 - val_accuracy: 0.4500 - val_loss: 1.3158\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5770 - loss: 1.0670 - val_accuracy: 0.5833 - val_loss: 0.9927\n",
      "Validation accuracy: 0.5833\n",
      "\n",
      "Training model with dropout=0.1, activation=relu, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.1671 - loss: 1.7973 - val_accuracy: 0.2417 - val_loss: 1.7876\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2206 - loss: 1.7854 - val_accuracy: 0.2333 - val_loss: 1.7817\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1959 - loss: 1.7817 - val_accuracy: 0.2750 - val_loss: 1.7653\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2632 - loss: 1.7660 - val_accuracy: 0.3833 - val_loss: 1.7404\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3162 - loss: 1.7355 - val_accuracy: 0.3083 - val_loss: 1.6996\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3038 - loss: 1.6922 - val_accuracy: 0.3500 - val_loss: 1.6326\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3286 - loss: 1.6448 - val_accuracy: 0.3500 - val_loss: 1.5785\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3521 - loss: 1.5763 - val_accuracy: 0.4000 - val_loss: 1.5161\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3773 - loss: 1.5101 - val_accuracy: 0.4333 - val_loss: 1.4546\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4263 - loss: 1.4498 - val_accuracy: 0.4750 - val_loss: 1.4037\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4298 - loss: 1.4373 - val_accuracy: 0.5250 - val_loss: 1.3558\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5030 - loss: 1.3812 - val_accuracy: 0.5000 - val_loss: 1.3253\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4911 - loss: 1.3343 - val_accuracy: 0.5000 - val_loss: 1.3250\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4876 - loss: 1.3184 - val_accuracy: 0.4833 - val_loss: 1.2782\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4523 - loss: 1.3526 - val_accuracy: 0.4667 - val_loss: 1.2462\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5042 - loss: 1.2665 - val_accuracy: 0.5667 - val_loss: 1.2208\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5500 - loss: 1.2263 - val_accuracy: 0.5083 - val_loss: 1.2004\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5127 - loss: 1.1957 - val_accuracy: 0.4917 - val_loss: 1.2138\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5239 - loss: 1.2167 - val_accuracy: 0.5083 - val_loss: 1.1872\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5326 - loss: 1.1933 - val_accuracy: 0.5667 - val_loss: 1.1252\n",
      "Validation accuracy: 0.5667\n",
      "\n",
      "Training model with dropout=0.1, activation=relu, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.1590 - loss: 1.7970 - val_accuracy: 0.1667 - val_loss: 1.7907\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.1992 - loss: 1.7867 - val_accuracy: 0.3083 - val_loss: 1.7873\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.2101 - loss: 1.7886 - val_accuracy: 0.2167 - val_loss: 1.7694\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.2045 - loss: 1.7659 - val_accuracy: 0.2000 - val_loss: 1.7280\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.2232 - loss: 1.7206 - val_accuracy: 0.3417 - val_loss: 1.6065\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.3310 - loss: 1.6040 - val_accuracy: 0.4333 - val_loss: 1.4575\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.3732 - loss: 1.5020 - val_accuracy: 0.4250 - val_loss: 1.3475\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.4392 - loss: 1.3702 - val_accuracy: 0.3917 - val_loss: 1.4168\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.4775 - loss: 1.2924 - val_accuracy: 0.5000 - val_loss: 1.2483\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.4959 - loss: 1.2389 - val_accuracy: 0.4417 - val_loss: 1.2521\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.4864 - loss: 1.2098 - val_accuracy: 0.5583 - val_loss: 1.0835\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5277 - loss: 1.1389 - val_accuracy: 0.4917 - val_loss: 1.1210\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.5253 - loss: 1.1088 - val_accuracy: 0.5750 - val_loss: 1.0065\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5551 - loss: 1.0380 - val_accuracy: 0.6000 - val_loss: 0.9980\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.6159 - loss: 1.0098 - val_accuracy: 0.5333 - val_loss: 1.0304\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5706 - loss: 1.0047 - val_accuracy: 0.5333 - val_loss: 1.0367\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.5615 - loss: 1.0253 - val_accuracy: 0.6000 - val_loss: 0.9415\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5678 - loss: 1.0297 - val_accuracy: 0.5333 - val_loss: 0.9701\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.6490 - loss: 0.8748 - val_accuracy: 0.5750 - val_loss: 0.9245\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.6405 - loss: 0.9186 - val_accuracy: 0.6250 - val_loss: 0.8842\n",
      "Validation accuracy: 0.6250\n",
      "\n",
      "Training model with dropout=0.1, activation=relu, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.1599 - loss: 1.7937 - val_accuracy: 0.1667 - val_loss: 1.7915\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1640 - loss: 1.7926 - val_accuracy: 0.1667 - val_loss: 1.7897\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2184 - loss: 1.7891 - val_accuracy: 0.1667 - val_loss: 1.7813\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2252 - loss: 1.7792 - val_accuracy: 0.2333 - val_loss: 1.7441\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2500 - loss: 1.7465 - val_accuracy: 0.2750 - val_loss: 1.6745\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2595 - loss: 1.6906 - val_accuracy: 0.3750 - val_loss: 1.5873\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3429 - loss: 1.5792 - val_accuracy: 0.4000 - val_loss: 1.4660\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3749 - loss: 1.5093 - val_accuracy: 0.3333 - val_loss: 1.4299\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3895 - loss: 1.4312 - val_accuracy: 0.4417 - val_loss: 1.3445\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4021 - loss: 1.3944 - val_accuracy: 0.4750 - val_loss: 1.3070\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4643 - loss: 1.3408 - val_accuracy: 0.2833 - val_loss: 1.5252\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3755 - loss: 1.4745 - val_accuracy: 0.4500 - val_loss: 1.2860\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4289 - loss: 1.3191 - val_accuracy: 0.4583 - val_loss: 1.2994\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4164 - loss: 1.3452 - val_accuracy: 0.4167 - val_loss: 1.2851\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.3295 - val_accuracy: 0.3667 - val_loss: 1.4012\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4242 - loss: 1.3415 - val_accuracy: 0.5000 - val_loss: 1.2374\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4580 - loss: 1.2872 - val_accuracy: 0.4667 - val_loss: 1.2632\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4331 - loss: 1.2887 - val_accuracy: 0.4000 - val_loss: 1.3691\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4396 - loss: 1.3126 - val_accuracy: 0.4667 - val_loss: 1.2445\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4767 - loss: 1.2633 - val_accuracy: 0.3667 - val_loss: 1.4180\n",
      "Validation accuracy: 0.3667\n",
      "\n",
      "Training model with dropout=0.1, activation=sigmoid, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.1515 - loss: 1.9136 - val_accuracy: 0.1667 - val_loss: 1.8535\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.1795 - loss: 1.8421 - val_accuracy: 0.1667 - val_loss: 1.7952\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.1399 - loss: 1.8142 - val_accuracy: 0.1667 - val_loss: 1.8643\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.1629 - loss: 1.8382 - val_accuracy: 0.1667 - val_loss: 1.8025\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.1788 - loss: 1.8040 - val_accuracy: 0.1667 - val_loss: 1.7978\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.1690 - loss: 1.8040 - val_accuracy: 0.1667 - val_loss: 1.8250\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.1983 - loss: 1.7950 - val_accuracy: 0.1750 - val_loss: 1.8128\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.1771 - loss: 1.8092 - val_accuracy: 0.2417 - val_loss: 1.7661\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2579 - loss: 1.7745 - val_accuracy: 0.1667 - val_loss: 1.7646\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.1991 - loss: 1.7673 - val_accuracy: 0.2500 - val_loss: 1.7454\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2610 - loss: 1.7579 - val_accuracy: 0.1917 - val_loss: 1.7411\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.2709 - loss: 1.7405 - val_accuracy: 0.2750 - val_loss: 1.7370\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.2295 - loss: 1.7448 - val_accuracy: 0.2750 - val_loss: 1.6807\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2854 - loss: 1.7060 - val_accuracy: 0.1667 - val_loss: 1.6819\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.2775 - loss: 1.6764 - val_accuracy: 0.4250 - val_loss: 1.6126\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.3840 - loss: 1.6341 - val_accuracy: 0.3417 - val_loss: 1.5824\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.3638 - loss: 1.6007 - val_accuracy: 0.2833 - val_loss: 1.6099\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.3339 - loss: 1.6056 - val_accuracy: 0.4000 - val_loss: 1.5256\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.4276 - loss: 1.5095 - val_accuracy: 0.3833 - val_loss: 1.4758\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.3894 - loss: 1.4754 - val_accuracy: 0.4250 - val_loss: 1.4162\n",
      "Validation accuracy: 0.4250\n",
      "\n",
      "Training model with dropout=0.1, activation=sigmoid, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.1629 - loss: 1.9243 - val_accuracy: 0.1667 - val_loss: 1.7988\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.1593 - loss: 1.8066 - val_accuracy: 0.1667 - val_loss: 1.8261\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.1672 - loss: 1.8144 - val_accuracy: 0.1667 - val_loss: 1.8083\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.1770 - loss: 1.8086 - val_accuracy: 0.1667 - val_loss: 1.7864\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.1749 - loss: 1.7926 - val_accuracy: 0.1667 - val_loss: 1.7839\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1766 - loss: 1.7902 - val_accuracy: 0.1667 - val_loss: 1.7749\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1681 - loss: 1.7832 - val_accuracy: 0.1667 - val_loss: 1.7753\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.1787 - loss: 1.7754 - val_accuracy: 0.2417 - val_loss: 1.7647\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.2231 - loss: 1.7672 - val_accuracy: 0.1667 - val_loss: 1.7648\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.1851 - loss: 1.7638 - val_accuracy: 0.2417 - val_loss: 1.7862\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2047 - loss: 1.7705 - val_accuracy: 0.2083 - val_loss: 1.7462\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.2745 - loss: 1.7477 - val_accuracy: 0.2750 - val_loss: 1.7298\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.2391 - loss: 1.7340 - val_accuracy: 0.2917 - val_loss: 1.7088\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.2899 - loss: 1.7023 - val_accuracy: 0.2667 - val_loss: 1.6893\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.2538 - loss: 1.7003 - val_accuracy: 0.3000 - val_loss: 1.6834\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.3068 - loss: 1.6716 - val_accuracy: 0.4083 - val_loss: 1.6485\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.3647 - loss: 1.6400 - val_accuracy: 0.3833 - val_loss: 1.6240\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.3877 - loss: 1.6108 - val_accuracy: 0.3833 - val_loss: 1.5622\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.3848 - loss: 1.5707 - val_accuracy: 0.3833 - val_loss: 1.5501\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3594 - loss: 1.5645 - val_accuracy: 0.3917 - val_loss: 1.5154\n",
      "Validation accuracy: 0.3917\n",
      "\n",
      "Training model with dropout=0.1, activation=sigmoid, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.1838 - loss: 1.8661 - val_accuracy: 0.1667 - val_loss: 1.7995\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1722 - loss: 1.8020 - val_accuracy: 0.1667 - val_loss: 1.7978\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1475 - loss: 1.8008 - val_accuracy: 0.2500 - val_loss: 1.7918\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1905 - loss: 1.7992 - val_accuracy: 0.1667 - val_loss: 1.7885\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1730 - loss: 1.7890 - val_accuracy: 0.1667 - val_loss: 1.7893\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1798 - loss: 1.7898 - val_accuracy: 0.1667 - val_loss: 1.7867\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1945 - loss: 1.7845 - val_accuracy: 0.1667 - val_loss: 1.7804\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1953 - loss: 1.7809 - val_accuracy: 0.2000 - val_loss: 1.7775\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1847 - loss: 1.7787 - val_accuracy: 0.1667 - val_loss: 1.7712\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1887 - loss: 1.7708 - val_accuracy: 0.1750 - val_loss: 1.7716\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2070 - loss: 1.7719 - val_accuracy: 0.1667 - val_loss: 1.7692\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2337 - loss: 1.7728 - val_accuracy: 0.2667 - val_loss: 1.7583\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2762 - loss: 1.7588 - val_accuracy: 0.3250 - val_loss: 1.7479\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2800 - loss: 1.7480 - val_accuracy: 0.2667 - val_loss: 1.7363\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3025 - loss: 1.7453 - val_accuracy: 0.3250 - val_loss: 1.7289\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3082 - loss: 1.7350 - val_accuracy: 0.3417 - val_loss: 1.7237\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3215 - loss: 1.7248 - val_accuracy: 0.4583 - val_loss: 1.7044\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4197 - loss: 1.6996 - val_accuracy: 0.2667 - val_loss: 1.6951\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3082 - loss: 1.7047 - val_accuracy: 0.3250 - val_loss: 1.6750\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3757 - loss: 1.6740 - val_accuracy: 0.3917 - val_loss: 1.6578\n",
      "Validation accuracy: 0.3917\n",
      "\n",
      "Training model with dropout=0.1, activation=sigmoid, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.1923 - loss: 1.8715 - val_accuracy: 0.1667 - val_loss: 1.8166\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.1701 - loss: 1.8212 - val_accuracy: 0.1667 - val_loss: 1.8047\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.1612 - loss: 1.8083 - val_accuracy: 0.1667 - val_loss: 1.8049\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.1371 - loss: 1.8056 - val_accuracy: 0.1667 - val_loss: 1.7927\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.1528 - loss: 1.8036 - val_accuracy: 0.1667 - val_loss: 1.7988\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.1485 - loss: 1.8082 - val_accuracy: 0.2000 - val_loss: 1.7924\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.1756 - loss: 1.7974 - val_accuracy: 0.1667 - val_loss: 1.8220\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.1694 - loss: 1.8205 - val_accuracy: 0.1667 - val_loss: 1.8054\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.1715 - loss: 1.8028 - val_accuracy: 0.1667 - val_loss: 1.7964\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.1723 - loss: 1.7957 - val_accuracy: 0.1667 - val_loss: 1.7911\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.1923 - loss: 1.7958 - val_accuracy: 0.1667 - val_loss: 1.7976\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.1775 - loss: 1.7961 - val_accuracy: 0.1667 - val_loss: 1.7937\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.1565 - loss: 1.8116 - val_accuracy: 0.1667 - val_loss: 1.8099\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.1477 - loss: 1.8007 - val_accuracy: 0.2333 - val_loss: 1.7883\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.1965 - loss: 1.7965 - val_accuracy: 0.1667 - val_loss: 1.7945\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.1785 - loss: 1.7865 - val_accuracy: 0.1667 - val_loss: 1.8006\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1628 - loss: 1.7888 - val_accuracy: 0.1750 - val_loss: 1.7554\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.2135 - loss: 1.7629 - val_accuracy: 0.1667 - val_loss: 1.7761\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.2092 - loss: 1.7590 - val_accuracy: 0.2750 - val_loss: 1.6936\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.2444 - loss: 1.6829 - val_accuracy: 0.2667 - val_loss: 1.6465\n",
      "Validation accuracy: 0.2667\n",
      "\n",
      "Training model with dropout=0.1, activation=sigmoid, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.1689 - loss: 1.8626 - val_accuracy: 0.1667 - val_loss: 1.8008\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1548 - loss: 1.8093 - val_accuracy: 0.1667 - val_loss: 1.7934\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1909 - loss: 1.7976 - val_accuracy: 0.1667 - val_loss: 1.8216\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1662 - loss: 1.8156 - val_accuracy: 0.1667 - val_loss: 1.8205\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1739 - loss: 1.8121 - val_accuracy: 0.1667 - val_loss: 1.8060\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1546 - loss: 1.8097 - val_accuracy: 0.1667 - val_loss: 1.7962\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1428 - loss: 1.8016 - val_accuracy: 0.1667 - val_loss: 1.8057\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1543 - loss: 1.8115 - val_accuracy: 0.1667 - val_loss: 1.7989\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1840 - loss: 1.7930 - val_accuracy: 0.1667 - val_loss: 1.8032\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1857 - loss: 1.7970 - val_accuracy: 0.1667 - val_loss: 1.8072\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1625 - loss: 1.8165 - val_accuracy: 0.1667 - val_loss: 1.7912\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1708 - loss: 1.7915 - val_accuracy: 0.1667 - val_loss: 1.7851\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1827 - loss: 1.7935 - val_accuracy: 0.1667 - val_loss: 1.8165\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1788 - loss: 1.8084 - val_accuracy: 0.2250 - val_loss: 1.7973\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1686 - loss: 1.7971 - val_accuracy: 0.2583 - val_loss: 1.7849\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1603 - loss: 1.7979 - val_accuracy: 0.1667 - val_loss: 1.7796\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1693 - loss: 1.7877 - val_accuracy: 0.1750 - val_loss: 1.7744\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1934 - loss: 1.7777 - val_accuracy: 0.2500 - val_loss: 1.7720\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2331 - loss: 1.7739 - val_accuracy: 0.3167 - val_loss: 1.7436\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2377 - loss: 1.7520 - val_accuracy: 0.2417 - val_loss: 1.7303\n",
      "Validation accuracy: 0.2417\n",
      "\n",
      "Training model with dropout=0.1, activation=tanh, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.1747 - loss: 1.8498 - val_accuracy: 0.2167 - val_loss: 1.7674\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.2542 - loss: 1.7599 - val_accuracy: 0.3250 - val_loss: 1.6664\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.3036 - loss: 1.6840 - val_accuracy: 0.2750 - val_loss: 1.5895\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3443 - loss: 1.5797 - val_accuracy: 0.4500 - val_loss: 1.3846\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4519 - loss: 1.3759 - val_accuracy: 0.4500 - val_loss: 1.2579\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.4454 - loss: 1.3198 - val_accuracy: 0.5167 - val_loss: 1.1252\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5283 - loss: 1.1852 - val_accuracy: 0.5250 - val_loss: 1.1813\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.5785 - loss: 1.0859 - val_accuracy: 0.5167 - val_loss: 1.1359\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.5864 - loss: 1.0632 - val_accuracy: 0.4500 - val_loss: 1.2364\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5538 - loss: 1.0851 - val_accuracy: 0.6000 - val_loss: 1.0322\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.6321 - loss: 0.9549 - val_accuracy: 0.5667 - val_loss: 1.0025\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.6446 - loss: 0.9185 - val_accuracy: 0.5667 - val_loss: 0.9660\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6690 - loss: 0.8662 - val_accuracy: 0.6250 - val_loss: 0.8853\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7155 - loss: 0.8181 - val_accuracy: 0.5500 - val_loss: 1.0346\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.7094 - loss: 0.7802 - val_accuracy: 0.6083 - val_loss: 1.0533\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.7046 - loss: 0.7796 - val_accuracy: 0.6417 - val_loss: 0.8364\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6980 - loss: 0.7809 - val_accuracy: 0.7167 - val_loss: 0.8352\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7399 - loss: 0.7501 - val_accuracy: 0.7250 - val_loss: 0.7365\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.7553 - loss: 0.7282 - val_accuracy: 0.3667 - val_loss: 1.6518\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6168 - loss: 1.0825 - val_accuracy: 0.6167 - val_loss: 0.8520\n",
      "Validation accuracy: 0.6167\n",
      "\n",
      "Training model with dropout=0.1, activation=tanh, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.1544 - loss: 1.8359 - val_accuracy: 0.1667 - val_loss: 1.7904\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.2164 - loss: 1.7758 - val_accuracy: 0.3667 - val_loss: 1.7115\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.2708 - loss: 1.7345 - val_accuracy: 0.3250 - val_loss: 1.6036\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.3430 - loss: 1.5971 - val_accuracy: 0.3417 - val_loss: 1.5282\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.4141 - loss: 1.5111 - val_accuracy: 0.3667 - val_loss: 1.6329\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.3810 - loss: 1.5238 - val_accuracy: 0.4583 - val_loss: 1.2980\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.4997 - loss: 1.2998 - val_accuracy: 0.4833 - val_loss: 1.2420\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.4946 - loss: 1.2183 - val_accuracy: 0.5000 - val_loss: 1.2311\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.5804 - loss: 1.1225 - val_accuracy: 0.6083 - val_loss: 1.0722\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5953 - loss: 1.0983 - val_accuracy: 0.5583 - val_loss: 1.0483\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.6358 - loss: 0.9806 - val_accuracy: 0.4917 - val_loss: 1.0560\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6050 - loss: 0.9785 - val_accuracy: 0.6500 - val_loss: 0.9910\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6896 - loss: 0.8976 - val_accuracy: 0.5833 - val_loss: 1.0113\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5893 - loss: 0.9983 - val_accuracy: 0.6000 - val_loss: 0.9557\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6648 - loss: 0.8761 - val_accuracy: 0.6667 - val_loss: 0.8511\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7040 - loss: 0.8486 - val_accuracy: 0.6167 - val_loss: 1.0443\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6838 - loss: 0.8401 - val_accuracy: 0.6167 - val_loss: 0.9147\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.7026 - loss: 0.7525 - val_accuracy: 0.7083 - val_loss: 0.8223\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7143 - loss: 0.7700 - val_accuracy: 0.6750 - val_loss: 0.9817\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7017 - loss: 0.7969 - val_accuracy: 0.5167 - val_loss: 1.1773\n",
      "Validation accuracy: 0.5167\n",
      "\n",
      "Training model with dropout=0.1, activation=tanh, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.1680 - loss: 1.8043 - val_accuracy: 0.1750 - val_loss: 1.7586\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2490 - loss: 1.7572 - val_accuracy: 0.2667 - val_loss: 1.6937\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2509 - loss: 1.7176 - val_accuracy: 0.2333 - val_loss: 1.6832\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3173 - loss: 1.6401 - val_accuracy: 0.4000 - val_loss: 1.5000\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3832 - loss: 1.5477 - val_accuracy: 0.5250 - val_loss: 1.3769\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4633 - loss: 1.3559 - val_accuracy: 0.5167 - val_loss: 1.2874\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5139 - loss: 1.2758 - val_accuracy: 0.4500 - val_loss: 1.2085\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5719 - loss: 1.1232 - val_accuracy: 0.5833 - val_loss: 1.1261\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5963 - loss: 1.0908 - val_accuracy: 0.5667 - val_loss: 1.0798\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5709 - loss: 1.0903 - val_accuracy: 0.5500 - val_loss: 1.0778\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6012 - loss: 1.0207 - val_accuracy: 0.5583 - val_loss: 1.0965\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6279 - loss: 0.9809 - val_accuracy: 0.5833 - val_loss: 1.0485\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6282 - loss: 1.0106 - val_accuracy: 0.6167 - val_loss: 0.9513\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6541 - loss: 0.9302 - val_accuracy: 0.6000 - val_loss: 0.9476\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6861 - loss: 0.8871 - val_accuracy: 0.6250 - val_loss: 0.9314\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6532 - loss: 0.8833 - val_accuracy: 0.6500 - val_loss: 0.9357\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6809 - loss: 0.8516 - val_accuracy: 0.5750 - val_loss: 0.9050\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6722 - loss: 0.8287 - val_accuracy: 0.6333 - val_loss: 0.8832\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7128 - loss: 0.8331 - val_accuracy: 0.7250 - val_loss: 0.8510\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7434 - loss: 0.7599 - val_accuracy: 0.7000 - val_loss: 0.7659\n",
      "Validation accuracy: 0.7000\n",
      "\n",
      "Training model with dropout=0.1, activation=tanh, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.1936 - loss: 1.8425 - val_accuracy: 0.3667 - val_loss: 1.6991\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.2357 - loss: 1.7220 - val_accuracy: 0.4167 - val_loss: 1.5870\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.3797 - loss: 1.5383 - val_accuracy: 0.4500 - val_loss: 1.3495\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.3781 - loss: 1.4412 - val_accuracy: 0.4500 - val_loss: 1.3027\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.5105 - loss: 1.2772 - val_accuracy: 0.3667 - val_loss: 1.4277\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.5016 - loss: 1.1837 - val_accuracy: 0.3750 - val_loss: 1.3805\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5394 - loss: 1.1317 - val_accuracy: 0.5167 - val_loss: 1.1746\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.5628 - loss: 1.1011 - val_accuracy: 0.5917 - val_loss: 1.1195\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.5671 - loss: 1.0484 - val_accuracy: 0.5333 - val_loss: 1.0201\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6048 - loss: 1.0387 - val_accuracy: 0.6083 - val_loss: 0.9191\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6745 - loss: 0.8692 - val_accuracy: 0.6417 - val_loss: 0.8593\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.6128 - loss: 0.9593 - val_accuracy: 0.5833 - val_loss: 0.9579\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.6094 - loss: 0.9287 - val_accuracy: 0.5667 - val_loss: 0.9496\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6758 - loss: 0.8185 - val_accuracy: 0.5333 - val_loss: 1.1339\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6520 - loss: 0.8867 - val_accuracy: 0.6417 - val_loss: 0.9117\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6915 - loss: 0.8043 - val_accuracy: 0.7167 - val_loss: 0.9192\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.7020 - loss: 0.8117 - val_accuracy: 0.7083 - val_loss: 0.7605\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.7170 - loss: 0.7581 - val_accuracy: 0.6000 - val_loss: 0.8789\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7495 - loss: 0.6780 - val_accuracy: 0.7333 - val_loss: 0.7449\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.7825 - loss: 0.6497 - val_accuracy: 0.6083 - val_loss: 0.9126\n",
      "Validation accuracy: 0.6083\n",
      "\n",
      "Training model with dropout=0.1, activation=tanh, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.1733 - loss: 1.8089 - val_accuracy: 0.2667 - val_loss: 1.7492\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2742 - loss: 1.7290 - val_accuracy: 0.3750 - val_loss: 1.5261\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3337 - loss: 1.5474 - val_accuracy: 0.3583 - val_loss: 1.4413\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4423 - loss: 1.4067 - val_accuracy: 0.4333 - val_loss: 1.2568\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4537 - loss: 1.2806 - val_accuracy: 0.4583 - val_loss: 1.1629\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5214 - loss: 1.1318 - val_accuracy: 0.5000 - val_loss: 1.1225\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5564 - loss: 1.0903 - val_accuracy: 0.5667 - val_loss: 1.0524\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6431 - loss: 0.9414 - val_accuracy: 0.4833 - val_loss: 1.2633\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6127 - loss: 0.9915 - val_accuracy: 0.6833 - val_loss: 0.9170\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6518 - loss: 0.9375 - val_accuracy: 0.5500 - val_loss: 1.3401\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6357 - loss: 0.9332 - val_accuracy: 0.5750 - val_loss: 0.9777\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6837 - loss: 0.8791 - val_accuracy: 0.5583 - val_loss: 0.8808\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6630 - loss: 0.8557 - val_accuracy: 0.6083 - val_loss: 0.9547\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6875 - loss: 0.8427 - val_accuracy: 0.4833 - val_loss: 1.2057\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5953 - loss: 0.9732 - val_accuracy: 0.6583 - val_loss: 0.8251\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6920 - loss: 0.8425 - val_accuracy: 0.6333 - val_loss: 0.8867\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7055 - loss: 0.7786 - val_accuracy: 0.7333 - val_loss: 0.7281\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7751 - loss: 0.6307 - val_accuracy: 0.7583 - val_loss: 0.6547\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7472 - loss: 0.6571 - val_accuracy: 0.7083 - val_loss: 0.7343\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7544 - loss: 0.6937 - val_accuracy: 0.6583 - val_loss: 0.9770\n",
      "Validation accuracy: 0.6583\n",
      "\n",
      "Training model with dropout=0.3, activation=relu, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.1712 - loss: 1.7949 - val_accuracy: 0.2250 - val_loss: 1.7896\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.2112 - loss: 1.7900 - val_accuracy: 0.1667 - val_loss: 1.7867\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.2059 - loss: 1.7851 - val_accuracy: 0.2500 - val_loss: 1.7725\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.2596 - loss: 1.7667 - val_accuracy: 0.2917 - val_loss: 1.7423\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.3048 - loss: 1.7336 - val_accuracy: 0.2833 - val_loss: 1.6788\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.3309 - loss: 1.6656 - val_accuracy: 0.3333 - val_loss: 1.5743\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.4028 - loss: 1.5459 - val_accuracy: 0.4833 - val_loss: 1.4378\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4108 - loss: 1.4909 - val_accuracy: 0.4167 - val_loss: 1.3838\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4384 - loss: 1.3847 - val_accuracy: 0.5000 - val_loss: 1.3117\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.4798 - loss: 1.3105 - val_accuracy: 0.4333 - val_loss: 1.3344\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4993 - loss: 1.2489 - val_accuracy: 0.5000 - val_loss: 1.2053\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.5647 - loss: 1.1907 - val_accuracy: 0.5000 - val_loss: 1.1598\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.5165 - loss: 1.1794 - val_accuracy: 0.5250 - val_loss: 1.1446\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.5751 - loss: 1.1211 - val_accuracy: 0.5500 - val_loss: 1.1162\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5676 - loss: 1.0912 - val_accuracy: 0.5583 - val_loss: 1.1084\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.5910 - loss: 1.0252 - val_accuracy: 0.6083 - val_loss: 1.0621\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6170 - loss: 1.0011 - val_accuracy: 0.6333 - val_loss: 1.0341\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.6111 - loss: 1.0191 - val_accuracy: 0.5917 - val_loss: 1.0028\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6225 - loss: 0.9784 - val_accuracy: 0.5833 - val_loss: 1.0024\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.6251 - loss: 0.9917 - val_accuracy: 0.5833 - val_loss: 1.0479\n",
      "Validation accuracy: 0.5833\n",
      "\n",
      "Training model with dropout=0.3, activation=relu, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.1851 - loss: 1.7950 - val_accuracy: 0.1667 - val_loss: 1.7860\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.2249 - loss: 1.7828 - val_accuracy: 0.2167 - val_loss: 1.7801\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.2139 - loss: 1.7871 - val_accuracy: 0.1750 - val_loss: 1.7663\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2313 - loss: 1.7650 - val_accuracy: 0.3667 - val_loss: 1.7372\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.3255 - loss: 1.7367 - val_accuracy: 0.2917 - val_loss: 1.6880\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.3516 - loss: 1.6903 - val_accuracy: 0.3333 - val_loss: 1.6140\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3576 - loss: 1.6346 - val_accuracy: 0.3917 - val_loss: 1.5350\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.3569 - loss: 1.5626 - val_accuracy: 0.4583 - val_loss: 1.4828\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.4071 - loss: 1.4776 - val_accuracy: 0.4500 - val_loss: 1.4132\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.4401 - loss: 1.4435 - val_accuracy: 0.4500 - val_loss: 1.3512\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.4437 - loss: 1.3877 - val_accuracy: 0.5000 - val_loss: 1.3191\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4802 - loss: 1.3134 - val_accuracy: 0.5333 - val_loss: 1.2823\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.4762 - loss: 1.3008 - val_accuracy: 0.5000 - val_loss: 1.2488\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.4892 - loss: 1.2673 - val_accuracy: 0.5167 - val_loss: 1.2022\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5123 - loss: 1.2515 - val_accuracy: 0.4667 - val_loss: 1.2740\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.5328 - loss: 1.2203 - val_accuracy: 0.5583 - val_loss: 1.1753\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5736 - loss: 1.1369 - val_accuracy: 0.5000 - val_loss: 1.1663\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.5738 - loss: 1.1299 - val_accuracy: 0.5417 - val_loss: 1.1059\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5891 - loss: 1.1002 - val_accuracy: 0.5917 - val_loss: 1.0658\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6093 - loss: 1.0368 - val_accuracy: 0.5583 - val_loss: 1.0598\n",
      "Validation accuracy: 0.5583\n",
      "\n",
      "Training model with dropout=0.3, activation=relu, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.1454 - loss: 1.7958 - val_accuracy: 0.1667 - val_loss: 1.7884\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1772 - loss: 1.7871 - val_accuracy: 0.1667 - val_loss: 1.7818\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2584 - loss: 1.7819 - val_accuracy: 0.3167 - val_loss: 1.7671\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2796 - loss: 1.7684 - val_accuracy: 0.3083 - val_loss: 1.7470\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3045 - loss: 1.7451 - val_accuracy: 0.3333 - val_loss: 1.7084\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2957 - loss: 1.7182 - val_accuracy: 0.3333 - val_loss: 1.6570\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3306 - loss: 1.6691 - val_accuracy: 0.3333 - val_loss: 1.6030\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3551 - loss: 1.6086 - val_accuracy: 0.3833 - val_loss: 1.5455\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3517 - loss: 1.5762 - val_accuracy: 0.4083 - val_loss: 1.4882\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3964 - loss: 1.4958 - val_accuracy: 0.4000 - val_loss: 1.4620\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3716 - loss: 1.5100 - val_accuracy: 0.3083 - val_loss: 1.4654\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3752 - loss: 1.4610 - val_accuracy: 0.4167 - val_loss: 1.3829\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4127 - loss: 1.4067 - val_accuracy: 0.4250 - val_loss: 1.3616\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4493 - loss: 1.3765 - val_accuracy: 0.5583 - val_loss: 1.3399\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4907 - loss: 1.3724 - val_accuracy: 0.4583 - val_loss: 1.3357\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4357 - loss: 1.3557 - val_accuracy: 0.4583 - val_loss: 1.3380\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5144 - loss: 1.3212 - val_accuracy: 0.5000 - val_loss: 1.2663\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5222 - loss: 1.2925 - val_accuracy: 0.4500 - val_loss: 1.2500\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5072 - loss: 1.2955 - val_accuracy: 0.5250 - val_loss: 1.2280\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5170 - loss: 1.2569 - val_accuracy: 0.5000 - val_loss: 1.2154\n",
      "Validation accuracy: 0.5000\n",
      "\n",
      "Training model with dropout=0.3, activation=relu, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.1888 - loss: 1.7966 - val_accuracy: 0.2000 - val_loss: 1.7896\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1843 - loss: 1.7882 - val_accuracy: 0.2167 - val_loss: 1.7842\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.2133 - loss: 1.7827 - val_accuracy: 0.2583 - val_loss: 1.7518\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2317 - loss: 1.7563 - val_accuracy: 0.3667 - val_loss: 1.6504\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.3215 - loss: 1.6429 - val_accuracy: 0.3917 - val_loss: 1.4868\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.3835 - loss: 1.5013 - val_accuracy: 0.4167 - val_loss: 1.4095\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.3966 - loss: 1.4147 - val_accuracy: 0.4333 - val_loss: 1.3134\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.3994 - loss: 1.4299 - val_accuracy: 0.5250 - val_loss: 1.2578\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4393 - loss: 1.3604 - val_accuracy: 0.3750 - val_loss: 1.2974\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.4830 - loss: 1.2518 - val_accuracy: 0.4417 - val_loss: 1.1899\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4674 - loss: 1.2522 - val_accuracy: 0.5417 - val_loss: 1.2022\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.5122 - loss: 1.2201 - val_accuracy: 0.5250 - val_loss: 1.1364\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5120 - loss: 1.2175 - val_accuracy: 0.5000 - val_loss: 1.2120\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4998 - loss: 1.2122 - val_accuracy: 0.5250 - val_loss: 1.1643\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.5518 - loss: 1.1283 - val_accuracy: 0.5083 - val_loss: 1.1041\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.5527 - loss: 1.1210 - val_accuracy: 0.5250 - val_loss: 1.1267\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.5474 - loss: 1.0723 - val_accuracy: 0.5833 - val_loss: 1.0481\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6110 - loss: 1.0457 - val_accuracy: 0.5417 - val_loss: 1.0724\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.6196 - loss: 1.0214 - val_accuracy: 0.6000 - val_loss: 1.0076\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6166 - loss: 0.9965 - val_accuracy: 0.5917 - val_loss: 0.9820\n",
      "Validation accuracy: 0.5917\n",
      "\n",
      "Training model with dropout=0.3, activation=relu, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.1706 - loss: 1.7948 - val_accuracy: 0.1667 - val_loss: 1.7915\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1717 - loss: 1.7923 - val_accuracy: 0.1667 - val_loss: 1.7904\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2026 - loss: 1.7906 - val_accuracy: 0.2250 - val_loss: 1.7851\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2127 - loss: 1.7798 - val_accuracy: 0.3167 - val_loss: 1.7379\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2650 - loss: 1.7318 - val_accuracy: 0.3167 - val_loss: 1.6134\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2792 - loss: 1.6150 - val_accuracy: 0.2833 - val_loss: 1.5056\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3799 - loss: 1.4709 - val_accuracy: 0.4583 - val_loss: 1.3904\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3975 - loss: 1.4339 - val_accuracy: 0.3750 - val_loss: 1.3822\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.3782 - loss: 1.4134 - val_accuracy: 0.3167 - val_loss: 1.4095\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4532 - loss: 1.3790 - val_accuracy: 0.4250 - val_loss: 1.3298\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4207 - loss: 1.3525 - val_accuracy: 0.4833 - val_loss: 1.2762\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4798 - loss: 1.2904 - val_accuracy: 0.3833 - val_loss: 1.2839\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4394 - loss: 1.2953 - val_accuracy: 0.4500 - val_loss: 1.2868\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4599 - loss: 1.2970 - val_accuracy: 0.5333 - val_loss: 1.2107\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5074 - loss: 1.2258 - val_accuracy: 0.5500 - val_loss: 1.2003\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4869 - loss: 1.2396 - val_accuracy: 0.5417 - val_loss: 1.1596\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5476 - loss: 1.1428 - val_accuracy: 0.4583 - val_loss: 1.1680\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5552 - loss: 1.1438 - val_accuracy: 0.5833 - val_loss: 1.1257\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5424 - loss: 1.1210 - val_accuracy: 0.5083 - val_loss: 1.1761\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5635 - loss: 1.1057 - val_accuracy: 0.5417 - val_loss: 1.0957\n",
      "Validation accuracy: 0.5417\n",
      "\n",
      "Training model with dropout=0.3, activation=sigmoid, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.1614 - loss: 1.8781 - val_accuracy: 0.1667 - val_loss: 1.8507\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1697 - loss: 1.8306 - val_accuracy: 0.1667 - val_loss: 1.8135\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.1942 - loss: 1.8178 - val_accuracy: 0.1667 - val_loss: 1.8042\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1772 - loss: 1.8026 - val_accuracy: 0.1667 - val_loss: 1.8649\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1841 - loss: 1.8131 - val_accuracy: 0.1667 - val_loss: 1.8155\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1746 - loss: 1.8115 - val_accuracy: 0.2583 - val_loss: 1.8836\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1821 - loss: 1.8408 - val_accuracy: 0.2000 - val_loss: 1.8061\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2333 - loss: 1.7840 - val_accuracy: 0.2500 - val_loss: 1.8359\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1987 - loss: 1.8096 - val_accuracy: 0.2083 - val_loss: 1.7708\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.1888 - loss: 1.7902 - val_accuracy: 0.3417 - val_loss: 1.7410\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.2848 - loss: 1.7488 - val_accuracy: 0.2417 - val_loss: 1.7289\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2506 - loss: 1.7334 - val_accuracy: 0.3917 - val_loss: 1.7042\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2654 - loss: 1.7276 - val_accuracy: 0.2583 - val_loss: 1.7024\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.2516 - loss: 1.7072 - val_accuracy: 0.3833 - val_loss: 1.6366\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3700 - loss: 1.6519 - val_accuracy: 0.3250 - val_loss: 1.6520\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3209 - loss: 1.6309 - val_accuracy: 0.2500 - val_loss: 1.5958\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.3187 - loss: 1.5994 - val_accuracy: 0.4000 - val_loss: 1.5665\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4078 - loss: 1.5445 - val_accuracy: 0.3833 - val_loss: 1.4992\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3684 - loss: 1.5133 - val_accuracy: 0.3583 - val_loss: 1.5064\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3863 - loss: 1.4768 - val_accuracy: 0.4333 - val_loss: 1.3943\n",
      "Validation accuracy: 0.4333\n",
      "\n",
      "Training model with dropout=0.3, activation=sigmoid, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.1705 - loss: 1.8508 - val_accuracy: 0.1667 - val_loss: 1.8019\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.1848 - loss: 1.8123 - val_accuracy: 0.1667 - val_loss: 1.8042\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.1579 - loss: 1.8157 - val_accuracy: 0.1667 - val_loss: 1.8073\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.1920 - loss: 1.8136 - val_accuracy: 0.1667 - val_loss: 1.7904\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1901 - loss: 1.7983 - val_accuracy: 0.2083 - val_loss: 1.7916\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.1923 - loss: 1.7781 - val_accuracy: 0.1667 - val_loss: 1.7718\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.1913 - loss: 1.7844 - val_accuracy: 0.1750 - val_loss: 1.7853\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.2541 - loss: 1.7755 - val_accuracy: 0.1667 - val_loss: 1.7630\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.1912 - loss: 1.7805 - val_accuracy: 0.1667 - val_loss: 1.7705\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.1961 - loss: 1.7705 - val_accuracy: 0.2750 - val_loss: 1.7429\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.2382 - loss: 1.7531 - val_accuracy: 0.2167 - val_loss: 1.7521\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.2174 - loss: 1.7422 - val_accuracy: 0.2083 - val_loss: 1.7403\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2614 - loss: 1.7362 - val_accuracy: 0.3750 - val_loss: 1.7073\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.3158 - loss: 1.7222 - val_accuracy: 0.3167 - val_loss: 1.6980\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.2870 - loss: 1.7088 - val_accuracy: 0.3250 - val_loss: 1.6734\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.3291 - loss: 1.6883 - val_accuracy: 0.3667 - val_loss: 1.6489\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.3814 - loss: 1.6526 - val_accuracy: 0.3083 - val_loss: 1.6341\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.2962 - loss: 1.6374 - val_accuracy: 0.3667 - val_loss: 1.5907\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.3653 - loss: 1.6086 - val_accuracy: 0.4917 - val_loss: 1.5615\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.4220 - loss: 1.5626 - val_accuracy: 0.4333 - val_loss: 1.5234\n",
      "Validation accuracy: 0.4333\n",
      "\n",
      "Training model with dropout=0.3, activation=sigmoid, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.1775 - loss: 1.8430 - val_accuracy: 0.1667 - val_loss: 1.8021\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1822 - loss: 1.8040 - val_accuracy: 0.1750 - val_loss: 1.8033\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1782 - loss: 1.8005 - val_accuracy: 0.1667 - val_loss: 1.7894\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1804 - loss: 1.7932 - val_accuracy: 0.1667 - val_loss: 1.7882\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1777 - loss: 1.7953 - val_accuracy: 0.1667 - val_loss: 1.7892\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1515 - loss: 1.7937 - val_accuracy: 0.1667 - val_loss: 1.7906\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1798 - loss: 1.7919 - val_accuracy: 0.2000 - val_loss: 1.7801\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2020 - loss: 1.7892 - val_accuracy: 0.3500 - val_loss: 1.7838\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2198 - loss: 1.7794 - val_accuracy: 0.2250 - val_loss: 1.7686\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2425 - loss: 1.7695 - val_accuracy: 0.2417 - val_loss: 1.7710\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.2416 - loss: 1.7792 - val_accuracy: 0.2583 - val_loss: 1.7659\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2611 - loss: 1.7684 - val_accuracy: 0.1917 - val_loss: 1.7636\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2407 - loss: 1.7623 - val_accuracy: 0.2333 - val_loss: 1.7556\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1847 - loss: 1.7589 - val_accuracy: 0.3333 - val_loss: 1.7399\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3016 - loss: 1.7450 - val_accuracy: 0.4667 - val_loss: 1.7281\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3074 - loss: 1.7374 - val_accuracy: 0.2000 - val_loss: 1.7282\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2221 - loss: 1.7260 - val_accuracy: 0.3833 - val_loss: 1.7138\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3189 - loss: 1.7179 - val_accuracy: 0.3667 - val_loss: 1.6922\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3458 - loss: 1.6986 - val_accuracy: 0.4417 - val_loss: 1.6796\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3867 - loss: 1.6802 - val_accuracy: 0.2500 - val_loss: 1.6827\n",
      "Validation accuracy: 0.2500\n",
      "\n",
      "Training model with dropout=0.3, activation=sigmoid, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.1629 - loss: 1.8739 - val_accuracy: 0.1667 - val_loss: 1.8229\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1601 - loss: 1.8301 - val_accuracy: 0.1667 - val_loss: 1.7984\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.1756 - loss: 1.8085 - val_accuracy: 0.1667 - val_loss: 1.8030\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.1425 - loss: 1.8057 - val_accuracy: 0.1667 - val_loss: 1.7964\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1735 - loss: 1.7956 - val_accuracy: 0.1667 - val_loss: 1.8110\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.1787 - loss: 1.7979 - val_accuracy: 0.1667 - val_loss: 1.7966\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1873 - loss: 1.8033 - val_accuracy: 0.1667 - val_loss: 1.8024\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1582 - loss: 1.8019 - val_accuracy: 0.1667 - val_loss: 1.7994\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.1730 - loss: 1.7988 - val_accuracy: 0.1667 - val_loss: 1.7914\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1672 - loss: 1.7965 - val_accuracy: 0.1667 - val_loss: 1.7982\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.1612 - loss: 1.7990 - val_accuracy: 0.1667 - val_loss: 1.7953\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.1648 - loss: 1.8016 - val_accuracy: 0.1667 - val_loss: 1.7981\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.1759 - loss: 1.8036 - val_accuracy: 0.2000 - val_loss: 1.7905\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.1661 - loss: 1.7932 - val_accuracy: 0.2500 - val_loss: 1.7830\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.2054 - loss: 1.7900 - val_accuracy: 0.1667 - val_loss: 1.7911\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2036 - loss: 1.7898 - val_accuracy: 0.2167 - val_loss: 1.8008\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.1614 - loss: 1.7902 - val_accuracy: 0.3083 - val_loss: 1.7504\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.2663 - loss: 1.7612 - val_accuracy: 0.2167 - val_loss: 1.7222\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.2230 - loss: 1.7279 - val_accuracy: 0.3333 - val_loss: 1.6665\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.3015 - loss: 1.6743 - val_accuracy: 0.3833 - val_loss: 1.5904\n",
      "Validation accuracy: 0.3833\n",
      "\n",
      "Training model with dropout=0.3, activation=sigmoid, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.1496 - loss: 1.8336 - val_accuracy: 0.1667 - val_loss: 1.8255\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1696 - loss: 1.8200 - val_accuracy: 0.1667 - val_loss: 1.7947\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.1503 - loss: 1.8116 - val_accuracy: 0.1667 - val_loss: 1.8150\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1424 - loss: 1.8084 - val_accuracy: 0.1667 - val_loss: 1.7939\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1769 - loss: 1.7994 - val_accuracy: 0.2333 - val_loss: 1.8083\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1671 - loss: 1.8210 - val_accuracy: 0.2667 - val_loss: 1.8103\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1891 - loss: 1.8076 - val_accuracy: 0.1667 - val_loss: 1.7957\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1674 - loss: 1.7985 - val_accuracy: 0.1667 - val_loss: 1.7962\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1576 - loss: 1.8053 - val_accuracy: 0.1667 - val_loss: 1.8023\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1793 - loss: 1.8028 - val_accuracy: 0.1667 - val_loss: 1.7923\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1775 - loss: 1.7950 - val_accuracy: 0.1667 - val_loss: 1.7965\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1547 - loss: 1.8010 - val_accuracy: 0.1667 - val_loss: 1.7966\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1674 - loss: 1.8023 - val_accuracy: 0.2000 - val_loss: 1.7890\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2122 - loss: 1.7932 - val_accuracy: 0.1667 - val_loss: 1.7889\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1664 - loss: 1.7927 - val_accuracy: 0.1667 - val_loss: 1.7770\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2026 - loss: 1.7769 - val_accuracy: 0.3250 - val_loss: 1.7688\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2144 - loss: 1.7749 - val_accuracy: 0.1667 - val_loss: 1.7722\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2090 - loss: 1.7651 - val_accuracy: 0.2500 - val_loss: 1.7342\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2779 - loss: 1.7408 - val_accuracy: 0.2583 - val_loss: 1.6887\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2824 - loss: 1.7020 - val_accuracy: 0.3417 - val_loss: 1.6314\n",
      "Validation accuracy: 0.3417\n",
      "\n",
      "Training model with dropout=0.3, activation=tanh, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.1717 - loss: 1.8250 - val_accuracy: 0.1667 - val_loss: 1.7877\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.2564 - loss: 1.7374 - val_accuracy: 0.3833 - val_loss: 1.5308\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.3366 - loss: 1.5807 - val_accuracy: 0.3833 - val_loss: 1.5105\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4201 - loss: 1.4489 - val_accuracy: 0.3583 - val_loss: 1.5167\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.4379 - loss: 1.3157 - val_accuracy: 0.4500 - val_loss: 1.3065\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.5303 - loss: 1.2219 - val_accuracy: 0.4333 - val_loss: 1.2549\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5246 - loss: 1.2240 - val_accuracy: 0.4917 - val_loss: 1.1578\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.6061 - loss: 1.0201 - val_accuracy: 0.5417 - val_loss: 1.0994\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.6420 - loss: 0.9588 - val_accuracy: 0.5750 - val_loss: 1.1432\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6383 - loss: 0.9869 - val_accuracy: 0.5833 - val_loss: 0.9761\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6589 - loss: 0.9278 - val_accuracy: 0.5333 - val_loss: 1.0968\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6506 - loss: 0.8944 - val_accuracy: 0.6917 - val_loss: 0.8101\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6864 - loss: 0.8484 - val_accuracy: 0.6167 - val_loss: 0.8762\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7032 - loss: 0.7934 - val_accuracy: 0.5833 - val_loss: 0.9843\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6771 - loss: 0.8597 - val_accuracy: 0.6167 - val_loss: 1.0046\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6331 - loss: 0.9623 - val_accuracy: 0.6417 - val_loss: 0.9133\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.6585 - loss: 0.8856 - val_accuracy: 0.7250 - val_loss: 0.7507\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7599 - loss: 0.6956 - val_accuracy: 0.6167 - val_loss: 1.0548\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.7011 - loss: 0.8059 - val_accuracy: 0.5750 - val_loss: 1.0158\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.7547 - loss: 0.6650 - val_accuracy: 0.7250 - val_loss: 0.6700\n",
      "Validation accuracy: 0.7250\n",
      "\n",
      "Training model with dropout=0.3, activation=tanh, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.1695 - loss: 1.8217 - val_accuracy: 0.1667 - val_loss: 1.7791\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.2253 - loss: 1.7543 - val_accuracy: 0.2583 - val_loss: 1.6678\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.3212 - loss: 1.6499 - val_accuracy: 0.2750 - val_loss: 1.6270\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.3234 - loss: 1.6052 - val_accuracy: 0.3333 - val_loss: 1.5053\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.4219 - loss: 1.4170 - val_accuracy: 0.5500 - val_loss: 1.2961\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4605 - loss: 1.3321 - val_accuracy: 0.5500 - val_loss: 1.2107\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.5071 - loss: 1.1930 - val_accuracy: 0.5417 - val_loss: 1.1098\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5934 - loss: 1.0773 - val_accuracy: 0.5917 - val_loss: 1.0711\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6069 - loss: 1.0053 - val_accuracy: 0.6000 - val_loss: 1.0089\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5926 - loss: 1.0044 - val_accuracy: 0.5500 - val_loss: 0.9789\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6464 - loss: 0.9304 - val_accuracy: 0.5500 - val_loss: 0.9465\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6337 - loss: 0.9291 - val_accuracy: 0.6750 - val_loss: 0.9785\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6373 - loss: 0.8985 - val_accuracy: 0.6167 - val_loss: 0.9561\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6442 - loss: 0.9114 - val_accuracy: 0.6833 - val_loss: 0.8903\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6721 - loss: 0.8485 - val_accuracy: 0.5417 - val_loss: 1.2457\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6615 - loss: 0.9499 - val_accuracy: 0.6417 - val_loss: 0.8233\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7062 - loss: 0.8072 - val_accuracy: 0.6833 - val_loss: 0.8377\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6934 - loss: 0.7600 - val_accuracy: 0.5750 - val_loss: 0.8784\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7372 - loss: 0.7399 - val_accuracy: 0.7250 - val_loss: 0.8047\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6976 - loss: 0.7910 - val_accuracy: 0.5167 - val_loss: 1.0431\n",
      "Validation accuracy: 0.5167\n",
      "\n",
      "Training model with dropout=0.3, activation=tanh, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.1628 - loss: 1.8080 - val_accuracy: 0.1667 - val_loss: 1.7550\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2201 - loss: 1.7570 - val_accuracy: 0.2250 - val_loss: 1.7176\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2612 - loss: 1.7002 - val_accuracy: 0.3917 - val_loss: 1.5896\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3413 - loss: 1.6118 - val_accuracy: 0.3500 - val_loss: 1.4774\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4102 - loss: 1.4763 - val_accuracy: 0.3583 - val_loss: 1.4173\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4423 - loss: 1.3726 - val_accuracy: 0.4750 - val_loss: 1.3045\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5317 - loss: 1.2594 - val_accuracy: 0.4833 - val_loss: 1.2396\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4953 - loss: 1.2496 - val_accuracy: 0.5583 - val_loss: 1.1335\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5580 - loss: 1.1323 - val_accuracy: 0.6000 - val_loss: 1.0733\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6147 - loss: 1.0672 - val_accuracy: 0.5750 - val_loss: 1.0284\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6428 - loss: 0.9849 - val_accuracy: 0.5750 - val_loss: 0.9978\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6720 - loss: 0.9107 - val_accuracy: 0.6167 - val_loss: 0.9862\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6705 - loss: 0.9116 - val_accuracy: 0.6167 - val_loss: 1.0074\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7109 - loss: 0.8630 - val_accuracy: 0.6417 - val_loss: 0.9068\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7002 - loss: 0.8114 - val_accuracy: 0.6750 - val_loss: 0.8818\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7023 - loss: 0.8719 - val_accuracy: 0.6750 - val_loss: 0.8677\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7005 - loss: 0.8540 - val_accuracy: 0.6917 - val_loss: 0.8660\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7156 - loss: 0.7748 - val_accuracy: 0.6833 - val_loss: 0.8141\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6847 - loss: 0.8278 - val_accuracy: 0.7250 - val_loss: 0.7830\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6894 - loss: 0.8587 - val_accuracy: 0.6917 - val_loss: 0.8044\n",
      "Validation accuracy: 0.6917\n",
      "\n",
      "Training model with dropout=0.3, activation=tanh, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.1575 - loss: 1.8314 - val_accuracy: 0.2333 - val_loss: 1.7573\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.2427 - loss: 1.7382 - val_accuracy: 0.3417 - val_loss: 1.5692\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.3186 - loss: 1.5914 - val_accuracy: 0.4833 - val_loss: 1.3176\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4438 - loss: 1.3767 - val_accuracy: 0.4167 - val_loss: 1.2193\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.4544 - loss: 1.2903 - val_accuracy: 0.4917 - val_loss: 1.3009\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.5612 - loss: 1.1568 - val_accuracy: 0.5500 - val_loss: 1.1497\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5394 - loss: 1.2285 - val_accuracy: 0.4167 - val_loss: 1.3179\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.5509 - loss: 1.1453 - val_accuracy: 0.5750 - val_loss: 1.1139\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.5772 - loss: 1.0103 - val_accuracy: 0.6583 - val_loss: 0.9333\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6283 - loss: 0.9575 - val_accuracy: 0.5500 - val_loss: 1.0113\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6324 - loss: 0.9551 - val_accuracy: 0.5167 - val_loss: 1.1230\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.6069 - loss: 0.9919 - val_accuracy: 0.6667 - val_loss: 0.8564\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6938 - loss: 0.8369 - val_accuracy: 0.6583 - val_loss: 0.8544\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6270 - loss: 0.9234 - val_accuracy: 0.5417 - val_loss: 1.1754\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.6092 - loss: 0.9787 - val_accuracy: 0.6167 - val_loss: 0.9285\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.7136 - loss: 0.7738 - val_accuracy: 0.6667 - val_loss: 0.8838\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7181 - loss: 0.7116 - val_accuracy: 0.6667 - val_loss: 0.7369\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.6731 - loss: 0.8339 - val_accuracy: 0.6750 - val_loss: 0.8787\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7111 - loss: 0.7414 - val_accuracy: 0.5583 - val_loss: 1.1662\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.6378 - loss: 1.0115 - val_accuracy: 0.6917 - val_loss: 0.7223\n",
      "Validation accuracy: 0.6917\n",
      "\n",
      "Training model with dropout=0.3, activation=tanh, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.1370 - loss: 1.8188 - val_accuracy: 0.2917 - val_loss: 1.7666\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2582 - loss: 1.7580 - val_accuracy: 0.2083 - val_loss: 1.6836\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2918 - loss: 1.6589 - val_accuracy: 0.3250 - val_loss: 1.4789\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4031 - loss: 1.4121 - val_accuracy: 0.4000 - val_loss: 1.3238\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4484 - loss: 1.3878 - val_accuracy: 0.5083 - val_loss: 1.2850\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4703 - loss: 1.2987 - val_accuracy: 0.4917 - val_loss: 1.2671\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.4842 - loss: 1.1987 - val_accuracy: 0.5583 - val_loss: 1.1204\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5508 - loss: 1.1236 - val_accuracy: 0.6000 - val_loss: 1.0703\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6104 - loss: 1.0416 - val_accuracy: 0.5500 - val_loss: 1.0599\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5952 - loss: 1.0301 - val_accuracy: 0.5417 - val_loss: 1.1529\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6048 - loss: 1.0080 - val_accuracy: 0.6417 - val_loss: 1.0526\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6436 - loss: 0.9748 - val_accuracy: 0.5500 - val_loss: 1.0831\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6584 - loss: 0.8853 - val_accuracy: 0.6333 - val_loss: 0.9635\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6584 - loss: 0.8789 - val_accuracy: 0.5917 - val_loss: 0.9613\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6724 - loss: 0.8312 - val_accuracy: 0.5583 - val_loss: 0.9939\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6535 - loss: 0.8576 - val_accuracy: 0.5833 - val_loss: 1.2287\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6184 - loss: 0.9824 - val_accuracy: 0.6000 - val_loss: 0.8635\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6476 - loss: 0.8786 - val_accuracy: 0.7250 - val_loss: 0.7864\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7351 - loss: 0.7604 - val_accuracy: 0.6750 - val_loss: 0.7858\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7510 - loss: 0.6672 - val_accuracy: 0.7000 - val_loss: 0.7574\n",
      "Validation accuracy: 0.7000\n",
      "\n",
      "Training model with dropout=0.5, activation=relu, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.1729 - loss: 1.7977 - val_accuracy: 0.1667 - val_loss: 1.7878\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1858 - loss: 1.7874 - val_accuracy: 0.1750 - val_loss: 1.7772\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.2248 - loss: 1.7757 - val_accuracy: 0.3250 - val_loss: 1.7478\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.2676 - loss: 1.7544 - val_accuracy: 0.3500 - val_loss: 1.6912\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3084 - loss: 1.6893 - val_accuracy: 0.2750 - val_loss: 1.6523\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.3503 - loss: 1.6179 - val_accuracy: 0.3750 - val_loss: 1.5407\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.3829 - loss: 1.5256 - val_accuracy: 0.4833 - val_loss: 1.4185\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.4166 - loss: 1.4233 - val_accuracy: 0.4000 - val_loss: 1.3562\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.4460 - loss: 1.3532 - val_accuracy: 0.5083 - val_loss: 1.2592\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.5246 - loss: 1.2544 - val_accuracy: 0.4333 - val_loss: 1.2635\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4887 - loss: 1.2446 - val_accuracy: 0.4917 - val_loss: 1.1902\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.5441 - loss: 1.1614 - val_accuracy: 0.5333 - val_loss: 1.1538\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5444 - loss: 1.1538 - val_accuracy: 0.5917 - val_loss: 1.0989\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5325 - loss: 1.1269 - val_accuracy: 0.5750 - val_loss: 1.0671\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.5723 - loss: 1.1033 - val_accuracy: 0.5250 - val_loss: 1.1074\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.5634 - loss: 1.0991 - val_accuracy: 0.5917 - val_loss: 1.0209\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6031 - loss: 1.0102 - val_accuracy: 0.5500 - val_loss: 1.0691\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.5880 - loss: 1.0633 - val_accuracy: 0.6083 - val_loss: 0.9988\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.6292 - loss: 0.9718 - val_accuracy: 0.5500 - val_loss: 1.0035\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6086 - loss: 0.9920 - val_accuracy: 0.5833 - val_loss: 0.9445\n",
      "Validation accuracy: 0.5833\n",
      "\n",
      "Training model with dropout=0.5, activation=relu, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.1519 - loss: 1.7947 - val_accuracy: 0.1833 - val_loss: 1.7856\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2019 - loss: 1.7824 - val_accuracy: 0.1750 - val_loss: 1.7765\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.2270 - loss: 1.7728 - val_accuracy: 0.1667 - val_loss: 1.7614\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.2352 - loss: 1.7501 - val_accuracy: 0.2833 - val_loss: 1.7196\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.3245 - loss: 1.7128 - val_accuracy: 0.3167 - val_loss: 1.6501\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.3388 - loss: 1.6554 - val_accuracy: 0.3500 - val_loss: 1.5769\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.3484 - loss: 1.5961 - val_accuracy: 0.3583 - val_loss: 1.5771\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.3823 - loss: 1.5553 - val_accuracy: 0.5000 - val_loss: 1.4453\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3922 - loss: 1.4617 - val_accuracy: 0.4667 - val_loss: 1.3929\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.4467 - loss: 1.4224 - val_accuracy: 0.4500 - val_loss: 1.3279\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.4728 - loss: 1.3369 - val_accuracy: 0.4750 - val_loss: 1.2699\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4975 - loss: 1.3210 - val_accuracy: 0.5333 - val_loss: 1.2349\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5715 - loss: 1.2372 - val_accuracy: 0.5250 - val_loss: 1.1870\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.4840 - loss: 1.2301 - val_accuracy: 0.5333 - val_loss: 1.2130\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5517 - loss: 1.1663 - val_accuracy: 0.5333 - val_loss: 1.1886\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.5283 - loss: 1.1440 - val_accuracy: 0.4917 - val_loss: 1.1463\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5678 - loss: 1.1346 - val_accuracy: 0.5667 - val_loss: 1.0761\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5769 - loss: 1.0945 - val_accuracy: 0.5500 - val_loss: 1.0926\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5879 - loss: 1.0563 - val_accuracy: 0.6083 - val_loss: 1.0252\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.5862 - loss: 1.0272 - val_accuracy: 0.5500 - val_loss: 1.0290\n",
      "Validation accuracy: 0.5500\n",
      "\n",
      "Training model with dropout=0.5, activation=relu, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.1661 - loss: 1.7947 - val_accuracy: 0.1667 - val_loss: 1.7908\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1939 - loss: 1.7895 - val_accuracy: 0.2917 - val_loss: 1.7864\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2694 - loss: 1.7865 - val_accuracy: 0.2667 - val_loss: 1.7804\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2149 - loss: 1.7797 - val_accuracy: 0.1667 - val_loss: 1.7782\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2190 - loss: 1.7762 - val_accuracy: 0.3417 - val_loss: 1.7543\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2652 - loss: 1.7536 - val_accuracy: 0.2917 - val_loss: 1.7315\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3325 - loss: 1.7335 - val_accuracy: 0.3667 - val_loss: 1.6930\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3273 - loss: 1.7003 - val_accuracy: 0.3250 - val_loss: 1.6509\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3541 - loss: 1.6543 - val_accuracy: 0.4250 - val_loss: 1.5975\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3779 - loss: 1.6061 - val_accuracy: 0.4167 - val_loss: 1.5515\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3651 - loss: 1.5650 - val_accuracy: 0.3250 - val_loss: 1.5507\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3960 - loss: 1.5131 - val_accuracy: 0.4333 - val_loss: 1.4596\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.4092 - loss: 1.4711 - val_accuracy: 0.4167 - val_loss: 1.4265\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4152 - loss: 1.4326 - val_accuracy: 0.4667 - val_loss: 1.3770\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4801 - loss: 1.3926 - val_accuracy: 0.4583 - val_loss: 1.3343\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4693 - loss: 1.3574 - val_accuracy: 0.5167 - val_loss: 1.3212\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5107 - loss: 1.2910 - val_accuracy: 0.4333 - val_loss: 1.2851\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4985 - loss: 1.2914 - val_accuracy: 0.5500 - val_loss: 1.2420\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5314 - loss: 1.2906 - val_accuracy: 0.5083 - val_loss: 1.2121\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5474 - loss: 1.2064 - val_accuracy: 0.5333 - val_loss: 1.2164\n",
      "Validation accuracy: 0.5333\n",
      "\n",
      "Training model with dropout=0.5, activation=relu, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.1559 - loss: 1.7949 - val_accuracy: 0.1833 - val_loss: 1.7891\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.1932 - loss: 1.7873 - val_accuracy: 0.2333 - val_loss: 1.7881\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.2072 - loss: 1.7804 - val_accuracy: 0.2667 - val_loss: 1.7307\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2750 - loss: 1.7191 - val_accuracy: 0.3750 - val_loss: 1.5687\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.3214 - loss: 1.5806 - val_accuracy: 0.2750 - val_loss: 1.6065\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.3411 - loss: 1.5653 - val_accuracy: 0.4167 - val_loss: 1.4152\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.4010 - loss: 1.4749 - val_accuracy: 0.2833 - val_loss: 1.6263\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3830 - loss: 1.4963 - val_accuracy: 0.4083 - val_loss: 1.3711\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.4019 - loss: 1.4260 - val_accuracy: 0.3833 - val_loss: 1.3597\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.4191 - loss: 1.3679 - val_accuracy: 0.3917 - val_loss: 1.3305\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.4470 - loss: 1.3641 - val_accuracy: 0.5083 - val_loss: 1.2310\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4567 - loss: 1.2995 - val_accuracy: 0.4500 - val_loss: 1.2215\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.4839 - loss: 1.2200 - val_accuracy: 0.5500 - val_loss: 1.1106\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.5148 - loss: 1.1663 - val_accuracy: 0.5167 - val_loss: 1.1837\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.5922 - loss: 1.0815 - val_accuracy: 0.5417 - val_loss: 1.1335\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.5522 - loss: 1.0789 - val_accuracy: 0.5833 - val_loss: 1.0237\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.6049 - loss: 0.9999 - val_accuracy: 0.5500 - val_loss: 1.0571\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.5878 - loss: 0.9837 - val_accuracy: 0.6083 - val_loss: 1.0190\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6176 - loss: 0.9533 - val_accuracy: 0.5667 - val_loss: 0.9664\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6210 - loss: 0.9418 - val_accuracy: 0.5333 - val_loss: 1.0679\n",
      "Validation accuracy: 0.5333\n",
      "\n",
      "Training model with dropout=0.5, activation=relu, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.1980 - loss: 1.7951 - val_accuracy: 0.1667 - val_loss: 1.7914\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1850 - loss: 1.7915 - val_accuracy: 0.2167 - val_loss: 1.7898\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2103 - loss: 1.7884 - val_accuracy: 0.2833 - val_loss: 1.7778\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.2152 - loss: 1.7769 - val_accuracy: 0.2500 - val_loss: 1.7263\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.2675 - loss: 1.7209 - val_accuracy: 0.3083 - val_loss: 1.6100\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3187 - loss: 1.6192 - val_accuracy: 0.3500 - val_loss: 1.4768\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3595 - loss: 1.4714 - val_accuracy: 0.3917 - val_loss: 1.4389\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3636 - loss: 1.4643 - val_accuracy: 0.3750 - val_loss: 1.3621\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4061 - loss: 1.3837 - val_accuracy: 0.4250 - val_loss: 1.3185\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4227 - loss: 1.3658 - val_accuracy: 0.4583 - val_loss: 1.2860\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4269 - loss: 1.3313 - val_accuracy: 0.4167 - val_loss: 1.2971\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4439 - loss: 1.3328 - val_accuracy: 0.4750 - val_loss: 1.2724\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4433 - loss: 1.2893 - val_accuracy: 0.4583 - val_loss: 1.2496\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4286 - loss: 1.2797 - val_accuracy: 0.4167 - val_loss: 1.2757\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4717 - loss: 1.3188 - val_accuracy: 0.4750 - val_loss: 1.2205\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4466 - loss: 1.2840 - val_accuracy: 0.4583 - val_loss: 1.2457\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4628 - loss: 1.2320 - val_accuracy: 0.3500 - val_loss: 1.4198\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4341 - loss: 1.2838 - val_accuracy: 0.4917 - val_loss: 1.1704\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4845 - loss: 1.2346 - val_accuracy: 0.4583 - val_loss: 1.1759\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5054 - loss: 1.1997 - val_accuracy: 0.4917 - val_loss: 1.1744\n",
      "Validation accuracy: 0.4917\n",
      "\n",
      "Training model with dropout=0.5, activation=sigmoid, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.1541 - loss: 1.9095 - val_accuracy: 0.1667 - val_loss: 1.8181\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.1508 - loss: 1.8171 - val_accuracy: 0.1667 - val_loss: 1.8215\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1708 - loss: 1.8426 - val_accuracy: 0.1667 - val_loss: 1.8671\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.1845 - loss: 1.8275 - val_accuracy: 0.1667 - val_loss: 1.8217\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.1606 - loss: 1.8299 - val_accuracy: 0.1667 - val_loss: 1.8004\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.1852 - loss: 1.7974 - val_accuracy: 0.1833 - val_loss: 1.7888\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1974 - loss: 1.8054 - val_accuracy: 0.1667 - val_loss: 1.7820\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1661 - loss: 1.7836 - val_accuracy: 0.1667 - val_loss: 1.7674\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1763 - loss: 1.7911 - val_accuracy: 0.1667 - val_loss: 1.7867\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.1871 - loss: 1.7850 - val_accuracy: 0.2667 - val_loss: 1.7469\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2500 - loss: 1.7477 - val_accuracy: 0.1667 - val_loss: 1.7684\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.2236 - loss: 1.7464 - val_accuracy: 0.2833 - val_loss: 1.7104\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2691 - loss: 1.7178 - val_accuracy: 0.2833 - val_loss: 1.6817\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.3016 - loss: 1.6958 - val_accuracy: 0.2833 - val_loss: 1.6584\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.3306 - loss: 1.6570 - val_accuracy: 0.4250 - val_loss: 1.6223\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.3455 - loss: 1.6222 - val_accuracy: 0.3167 - val_loss: 1.5832\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3577 - loss: 1.5986 - val_accuracy: 0.4167 - val_loss: 1.5426\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.3509 - loss: 1.5734 - val_accuracy: 0.4250 - val_loss: 1.4960\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.4072 - loss: 1.5099 - val_accuracy: 0.4083 - val_loss: 1.4368\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.3999 - loss: 1.4733 - val_accuracy: 0.3750 - val_loss: 1.4728\n",
      "Validation accuracy: 0.3750\n",
      "\n",
      "Training model with dropout=0.5, activation=sigmoid, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.1483 - loss: 1.8446 - val_accuracy: 0.1667 - val_loss: 1.7983\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.1563 - loss: 1.8156 - val_accuracy: 0.1667 - val_loss: 1.7946\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1429 - loss: 1.8056 - val_accuracy: 0.2417 - val_loss: 1.7920\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1708 - loss: 1.7935 - val_accuracy: 0.1667 - val_loss: 1.7952\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.1724 - loss: 1.7998 - val_accuracy: 0.1667 - val_loss: 1.8214\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.1889 - loss: 1.7976 - val_accuracy: 0.1917 - val_loss: 1.7860\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.1735 - loss: 1.7930 - val_accuracy: 0.1750 - val_loss: 1.7854\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.1913 - loss: 1.7908 - val_accuracy: 0.3333 - val_loss: 1.7728\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.2666 - loss: 1.7771 - val_accuracy: 0.2333 - val_loss: 1.7658\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.2207 - loss: 1.7692 - val_accuracy: 0.2167 - val_loss: 1.7624\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.2139 - loss: 1.7698 - val_accuracy: 0.1750 - val_loss: 1.7562\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.2206 - loss: 1.7462 - val_accuracy: 0.3250 - val_loss: 1.7305\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.2619 - loss: 1.7443 - val_accuracy: 0.1667 - val_loss: 1.7335\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.2887 - loss: 1.7274 - val_accuracy: 0.2333 - val_loss: 1.7077\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.2556 - loss: 1.7133 - val_accuracy: 0.3167 - val_loss: 1.7029\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.3433 - loss: 1.6947 - val_accuracy: 0.3167 - val_loss: 1.6598\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.3432 - loss: 1.6600 - val_accuracy: 0.3000 - val_loss: 1.6377\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.3414 - loss: 1.6412 - val_accuracy: 0.3500 - val_loss: 1.6140\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.3078 - loss: 1.6404 - val_accuracy: 0.3833 - val_loss: 1.5802\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.3897 - loss: 1.5837 - val_accuracy: 0.3333 - val_loss: 1.5690\n",
      "Validation accuracy: 0.3333\n",
      "\n",
      "Training model with dropout=0.5, activation=sigmoid, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.1602 - loss: 1.8204 - val_accuracy: 0.1667 - val_loss: 1.7988\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1778 - loss: 1.7984 - val_accuracy: 0.1667 - val_loss: 1.8024\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1686 - loss: 1.8020 - val_accuracy: 0.1667 - val_loss: 1.7928\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.1906 - loss: 1.7893 - val_accuracy: 0.1917 - val_loss: 1.7877\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1836 - loss: 1.7969 - val_accuracy: 0.1667 - val_loss: 1.7829\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1933 - loss: 1.7881 - val_accuracy: 0.1667 - val_loss: 1.7879\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1720 - loss: 1.7912 - val_accuracy: 0.1917 - val_loss: 1.7777\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1863 - loss: 1.7825 - val_accuracy: 0.2250 - val_loss: 1.7790\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2342 - loss: 1.7742 - val_accuracy: 0.1750 - val_loss: 1.7676\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1927 - loss: 1.7691 - val_accuracy: 0.3333 - val_loss: 1.7612\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3005 - loss: 1.7652 - val_accuracy: 0.4000 - val_loss: 1.7575\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2235 - loss: 1.7696 - val_accuracy: 0.1667 - val_loss: 1.7656\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1916 - loss: 1.7690 - val_accuracy: 0.3583 - val_loss: 1.7413\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.2697 - loss: 1.7485 - val_accuracy: 0.3333 - val_loss: 1.7359\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3104 - loss: 1.7381 - val_accuracy: 0.4083 - val_loss: 1.7216\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3476 - loss: 1.7298 - val_accuracy: 0.3667 - val_loss: 1.7113\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3650 - loss: 1.7178 - val_accuracy: 0.3417 - val_loss: 1.6944\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3465 - loss: 1.7037 - val_accuracy: 0.3667 - val_loss: 1.6859\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3988 - loss: 1.6828 - val_accuracy: 0.4083 - val_loss: 1.6593\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3505 - loss: 1.6779 - val_accuracy: 0.3000 - val_loss: 1.6524\n",
      "Validation accuracy: 0.3000\n",
      "\n",
      "Training model with dropout=0.5, activation=sigmoid, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.1493 - loss: 1.8726 - val_accuracy: 0.1667 - val_loss: 1.8102\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.1699 - loss: 1.8126 - val_accuracy: 0.1667 - val_loss: 1.8039\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.1653 - loss: 1.8041 - val_accuracy: 0.1667 - val_loss: 1.7999\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.1621 - loss: 1.8015 - val_accuracy: 0.1667 - val_loss: 1.8098\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.1698 - loss: 1.8124 - val_accuracy: 0.1667 - val_loss: 1.7958\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1585 - loss: 1.8044 - val_accuracy: 0.1667 - val_loss: 1.8028\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1676 - loss: 1.8028 - val_accuracy: 0.1667 - val_loss: 1.7965\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.1577 - loss: 1.7965 - val_accuracy: 0.1667 - val_loss: 1.8090\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.1516 - loss: 1.8073 - val_accuracy: 0.1667 - val_loss: 1.7965\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.1768 - loss: 1.7992 - val_accuracy: 0.1667 - val_loss: 1.8042\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.1777 - loss: 1.8007 - val_accuracy: 0.1667 - val_loss: 1.7952\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.1520 - loss: 1.7960 - val_accuracy: 0.1667 - val_loss: 1.8024\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.1681 - loss: 1.7979 - val_accuracy: 0.1667 - val_loss: 1.7903\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2095 - loss: 1.7875 - val_accuracy: 0.1667 - val_loss: 1.7960\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.1841 - loss: 1.7973 - val_accuracy: 0.1667 - val_loss: 1.7911\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.1874 - loss: 1.7880 - val_accuracy: 0.1667 - val_loss: 1.7812\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.1739 - loss: 1.7858 - val_accuracy: 0.2583 - val_loss: 1.7670\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.2192 - loss: 1.7762 - val_accuracy: 0.2250 - val_loss: 1.7403\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.2067 - loss: 1.7637 - val_accuracy: 0.2833 - val_loss: 1.7379\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.2854 - loss: 1.7262 - val_accuracy: 0.3250 - val_loss: 1.6159\n",
      "Validation accuracy: 0.3250\n",
      "\n",
      "Training model with dropout=0.5, activation=sigmoid, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.1663 - loss: 1.8649 - val_accuracy: 0.1667 - val_loss: 1.8080\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1699 - loss: 1.8101 - val_accuracy: 0.1667 - val_loss: 1.8059\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1842 - loss: 1.8045 - val_accuracy: 0.1667 - val_loss: 1.8160\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1566 - loss: 1.8102 - val_accuracy: 0.1667 - val_loss: 1.8117\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1560 - loss: 1.8195 - val_accuracy: 0.1667 - val_loss: 1.8283\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1753 - loss: 1.8156 - val_accuracy: 0.1667 - val_loss: 1.8064\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1705 - loss: 1.8047 - val_accuracy: 0.1667 - val_loss: 1.8010\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1375 - loss: 1.8103 - val_accuracy: 0.1667 - val_loss: 1.7971\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1915 - loss: 1.7905 - val_accuracy: 0.2833 - val_loss: 1.8100\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1815 - loss: 1.8160 - val_accuracy: 0.1667 - val_loss: 1.8245\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1978 - loss: 1.8077 - val_accuracy: 0.1667 - val_loss: 1.8036\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1649 - loss: 1.7936 - val_accuracy: 0.1917 - val_loss: 1.7991\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1528 - loss: 1.8041 - val_accuracy: 0.1667 - val_loss: 1.7903\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1594 - loss: 1.7984 - val_accuracy: 0.1667 - val_loss: 1.7874\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1715 - loss: 1.7978 - val_accuracy: 0.1667 - val_loss: 1.7971\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1851 - loss: 1.7901 - val_accuracy: 0.1667 - val_loss: 1.7884\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1742 - loss: 1.7934 - val_accuracy: 0.1833 - val_loss: 1.7802\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1841 - loss: 1.7842 - val_accuracy: 0.2750 - val_loss: 1.7782\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2102 - loss: 1.7814 - val_accuracy: 0.1667 - val_loss: 1.7655\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2386 - loss: 1.7665 - val_accuracy: 0.3667 - val_loss: 1.7501\n",
      "Validation accuracy: 0.3667\n",
      "\n",
      "Training model with dropout=0.5, activation=tanh, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.2118 - loss: 1.8170 - val_accuracy: 0.1667 - val_loss: 1.7628\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2172 - loss: 1.7502 - val_accuracy: 0.2333 - val_loss: 1.6896\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2771 - loss: 1.6608 - val_accuracy: 0.4417 - val_loss: 1.5064\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.3802 - loss: 1.5133 - val_accuracy: 0.4583 - val_loss: 1.3006\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4320 - loss: 1.3630 - val_accuracy: 0.5583 - val_loss: 1.1923\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4946 - loss: 1.2671 - val_accuracy: 0.5000 - val_loss: 1.3210\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5340 - loss: 1.1927 - val_accuracy: 0.4667 - val_loss: 1.1850\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.5619 - loss: 1.1213 - val_accuracy: 0.4833 - val_loss: 1.0930\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.5939 - loss: 1.1068 - val_accuracy: 0.5833 - val_loss: 1.0687\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6224 - loss: 1.0241 - val_accuracy: 0.5333 - val_loss: 1.0483\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6481 - loss: 0.9351 - val_accuracy: 0.6750 - val_loss: 0.8955\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.6524 - loss: 0.9508 - val_accuracy: 0.6083 - val_loss: 0.8933\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6885 - loss: 0.8093 - val_accuracy: 0.7083 - val_loss: 0.8373\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6923 - loss: 0.8219 - val_accuracy: 0.7083 - val_loss: 0.8670\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7212 - loss: 0.7752 - val_accuracy: 0.6583 - val_loss: 0.8362\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.7031 - loss: 0.7902 - val_accuracy: 0.6667 - val_loss: 0.9077\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6904 - loss: 0.9087 - val_accuracy: 0.6083 - val_loss: 0.9514\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7382 - loss: 0.7098 - val_accuracy: 0.7667 - val_loss: 0.7865\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7811 - loss: 0.6545 - val_accuracy: 0.6250 - val_loss: 0.9377\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.7344 - loss: 0.7048 - val_accuracy: 0.8167 - val_loss: 0.6470\n",
      "Validation accuracy: 0.8167\n",
      "\n",
      "Training model with dropout=0.5, activation=tanh, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.1736 - loss: 1.8091 - val_accuracy: 0.3083 - val_loss: 1.7429\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.2690 - loss: 1.7472 - val_accuracy: 0.2500 - val_loss: 1.6678\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.3058 - loss: 1.6385 - val_accuracy: 0.4417 - val_loss: 1.4745\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4195 - loss: 1.4820 - val_accuracy: 0.3667 - val_loss: 1.4492\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4120 - loss: 1.3970 - val_accuracy: 0.4500 - val_loss: 1.3230\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.4849 - loss: 1.3068 - val_accuracy: 0.5000 - val_loss: 1.1922\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5431 - loss: 1.1808 - val_accuracy: 0.5250 - val_loss: 1.0553\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5943 - loss: 1.0759 - val_accuracy: 0.5583 - val_loss: 1.0926\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5439 - loss: 1.1463 - val_accuracy: 0.5333 - val_loss: 1.0865\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6144 - loss: 0.9959 - val_accuracy: 0.6333 - val_loss: 0.9114\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6643 - loss: 0.8739 - val_accuracy: 0.6000 - val_loss: 0.8722\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.6209 - loss: 0.9107 - val_accuracy: 0.5500 - val_loss: 0.9255\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6576 - loss: 0.8404 - val_accuracy: 0.7083 - val_loss: 0.8030\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7121 - loss: 0.7884 - val_accuracy: 0.5917 - val_loss: 1.0677\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.6279 - loss: 0.9659 - val_accuracy: 0.5833 - val_loss: 1.0425\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6717 - loss: 0.8125 - val_accuracy: 0.5250 - val_loss: 0.9316\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.7586 - loss: 0.7161 - val_accuracy: 0.6917 - val_loss: 0.8055\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.7337 - loss: 0.7305 - val_accuracy: 0.6667 - val_loss: 0.8709\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7121 - loss: 0.7325 - val_accuracy: 0.5000 - val_loss: 1.0744\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.6973 - loss: 0.7720 - val_accuracy: 0.5667 - val_loss: 0.9665\n",
      "Validation accuracy: 0.5667\n",
      "\n",
      "Training model with dropout=0.5, activation=tanh, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.1646 - loss: 1.8106 - val_accuracy: 0.1667 - val_loss: 1.7716\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2195 - loss: 1.7732 - val_accuracy: 0.3833 - val_loss: 1.7187\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2906 - loss: 1.7073 - val_accuracy: 0.3667 - val_loss: 1.6051\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3615 - loss: 1.6162 - val_accuracy: 0.3833 - val_loss: 1.4769\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4432 - loss: 1.4331 - val_accuracy: 0.5417 - val_loss: 1.3227\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4729 - loss: 1.3512 - val_accuracy: 0.5083 - val_loss: 1.3174\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5556 - loss: 1.2202 - val_accuracy: 0.5583 - val_loss: 1.1226\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5817 - loss: 1.1390 - val_accuracy: 0.4917 - val_loss: 1.2476\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5750 - loss: 1.1059 - val_accuracy: 0.5250 - val_loss: 1.0903\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5870 - loss: 1.0072 - val_accuracy: 0.5250 - val_loss: 0.9982\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6280 - loss: 0.9685 - val_accuracy: 0.5583 - val_loss: 1.0590\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6074 - loss: 1.0133 - val_accuracy: 0.6167 - val_loss: 0.9621\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6377 - loss: 0.9324 - val_accuracy: 0.5667 - val_loss: 1.0578\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6154 - loss: 0.9680 - val_accuracy: 0.5833 - val_loss: 0.9957\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6828 - loss: 0.8461 - val_accuracy: 0.6333 - val_loss: 0.9111\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6878 - loss: 0.8369 - val_accuracy: 0.5917 - val_loss: 0.9503\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7071 - loss: 0.7978 - val_accuracy: 0.6583 - val_loss: 0.9656\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7085 - loss: 0.7835 - val_accuracy: 0.6833 - val_loss: 0.8271\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7080 - loss: 0.7943 - val_accuracy: 0.6583 - val_loss: 0.9537\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7199 - loss: 0.8035 - val_accuracy: 0.6667 - val_loss: 0.8241\n",
      "Validation accuracy: 0.6667\n",
      "\n",
      "Training model with dropout=0.5, activation=tanh, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.1787 - loss: 1.8195 - val_accuracy: 0.2583 - val_loss: 1.7255\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.2263 - loss: 1.7471 - val_accuracy: 0.4583 - val_loss: 1.5281\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3462 - loss: 1.5499 - val_accuracy: 0.4667 - val_loss: 1.3506\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.4295 - loss: 1.3947 - val_accuracy: 0.4917 - val_loss: 1.2243\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4539 - loss: 1.2864 - val_accuracy: 0.4833 - val_loss: 1.1297\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5489 - loss: 1.1163 - val_accuracy: 0.4750 - val_loss: 1.3167\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5254 - loss: 1.1890 - val_accuracy: 0.5000 - val_loss: 1.2588\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.5038 - loss: 1.2772 - val_accuracy: 0.5667 - val_loss: 1.0440\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6497 - loss: 0.9591 - val_accuracy: 0.5333 - val_loss: 1.0090\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5862 - loss: 0.9890 - val_accuracy: 0.4333 - val_loss: 1.2385\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.5511 - loss: 1.1128 - val_accuracy: 0.5500 - val_loss: 1.0389\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6682 - loss: 0.8826 - val_accuracy: 0.5833 - val_loss: 1.0954\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6334 - loss: 0.9732 - val_accuracy: 0.6083 - val_loss: 0.8959\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6589 - loss: 0.8438 - val_accuracy: 0.6167 - val_loss: 0.9448\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6589 - loss: 0.8613 - val_accuracy: 0.6250 - val_loss: 0.8677\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6769 - loss: 0.7904 - val_accuracy: 0.6417 - val_loss: 0.9259\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.6700 - loss: 0.8171 - val_accuracy: 0.6500 - val_loss: 0.8218\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.6999 - loss: 0.8209 - val_accuracy: 0.5917 - val_loss: 1.3114\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.6859 - loss: 0.9180 - val_accuracy: 0.6000 - val_loss: 1.0030\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.7289 - loss: 0.7323 - val_accuracy: 0.6917 - val_loss: 0.8444\n",
      "Validation accuracy: 0.6917\n",
      "\n",
      "Training model with dropout=0.5, activation=tanh, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.1580 - loss: 1.8107 - val_accuracy: 0.1667 - val_loss: 1.7838\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1855 - loss: 1.7901 - val_accuracy: 0.1667 - val_loss: 1.8157\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.2389 - loss: 1.7653 - val_accuracy: 0.4333 - val_loss: 1.5927\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4420 - loss: 1.5166 - val_accuracy: 0.2500 - val_loss: 1.7193\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4315 - loss: 1.4044 - val_accuracy: 0.5083 - val_loss: 1.2166\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5632 - loss: 1.1690 - val_accuracy: 0.5417 - val_loss: 1.0840\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5581 - loss: 1.1060 - val_accuracy: 0.5833 - val_loss: 1.0757\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5856 - loss: 1.0578 - val_accuracy: 0.5750 - val_loss: 1.0171\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5720 - loss: 1.0210 - val_accuracy: 0.6583 - val_loss: 0.9911\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6010 - loss: 1.0102 - val_accuracy: 0.6083 - val_loss: 0.9410\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6397 - loss: 0.9017 - val_accuracy: 0.6167 - val_loss: 0.9915\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5873 - loss: 1.0577 - val_accuracy: 0.5917 - val_loss: 0.9328\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6402 - loss: 0.9169 - val_accuracy: 0.5250 - val_loss: 1.1479\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6769 - loss: 0.8621 - val_accuracy: 0.7500 - val_loss: 0.8054\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6888 - loss: 0.8175 - val_accuracy: 0.6833 - val_loss: 0.7457\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6723 - loss: 0.8466 - val_accuracy: 0.6250 - val_loss: 0.9273\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6617 - loss: 0.7967 - val_accuracy: 0.6333 - val_loss: 1.0128\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7291 - loss: 0.7042 - val_accuracy: 0.6750 - val_loss: 0.7966\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7508 - loss: 0.6765 - val_accuracy: 0.7417 - val_loss: 0.7588\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7184 - loss: 0.7208 - val_accuracy: 0.6500 - val_loss: 0.7982\n",
      "Validation accuracy: 0.6500\n",
      "\n",
      "Training model with dropout=0.7, activation=relu, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.1598 - loss: 1.7992 - val_accuracy: 0.2417 - val_loss: 1.7901\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1748 - loss: 1.7914 - val_accuracy: 0.3250 - val_loss: 1.7773\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.2198 - loss: 1.7775 - val_accuracy: 0.3333 - val_loss: 1.7477\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.2765 - loss: 1.7497 - val_accuracy: 0.2833 - val_loss: 1.6950\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2706 - loss: 1.6951 - val_accuracy: 0.3417 - val_loss: 1.6127\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.3493 - loss: 1.6131 - val_accuracy: 0.3000 - val_loss: 1.5503\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.3675 - loss: 1.5357 - val_accuracy: 0.4500 - val_loss: 1.4072\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4247 - loss: 1.4594 - val_accuracy: 0.5000 - val_loss: 1.3679\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.4618 - loss: 1.3532 - val_accuracy: 0.4333 - val_loss: 1.3624\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.4943 - loss: 1.2723 - val_accuracy: 0.4917 - val_loss: 1.2263\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.5437 - loss: 1.2195 - val_accuracy: 0.5250 - val_loss: 1.2395\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.5142 - loss: 1.2086 - val_accuracy: 0.5500 - val_loss: 1.1442\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.5296 - loss: 1.1526 - val_accuracy: 0.5500 - val_loss: 1.1828\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5597 - loss: 1.0748 - val_accuracy: 0.5417 - val_loss: 1.1596\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5430 - loss: 1.1207 - val_accuracy: 0.5250 - val_loss: 1.0948\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5926 - loss: 1.0422 - val_accuracy: 0.5583 - val_loss: 1.0774\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6229 - loss: 1.0287 - val_accuracy: 0.6000 - val_loss: 0.9960\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6284 - loss: 0.9920 - val_accuracy: 0.6333 - val_loss: 0.9811\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6597 - loss: 0.9761 - val_accuracy: 0.6000 - val_loss: 0.9806\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6231 - loss: 0.9637 - val_accuracy: 0.6417 - val_loss: 1.0270\n",
      "Validation accuracy: 0.6417\n",
      "\n",
      "Training model with dropout=0.7, activation=relu, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.1692 - loss: 1.7949 - val_accuracy: 0.1667 - val_loss: 1.7886\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.1741 - loss: 1.7910 - val_accuracy: 0.3000 - val_loss: 1.7829\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.2369 - loss: 1.7807 - val_accuracy: 0.1750 - val_loss: 1.7845\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2582 - loss: 1.7723 - val_accuracy: 0.2833 - val_loss: 1.7506\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.2428 - loss: 1.7537 - val_accuracy: 0.3833 - val_loss: 1.7092\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3146 - loss: 1.7134 - val_accuracy: 0.3500 - val_loss: 1.6370\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.3556 - loss: 1.6326 - val_accuracy: 0.4167 - val_loss: 1.5762\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.4152 - loss: 1.5578 - val_accuracy: 0.3583 - val_loss: 1.4933\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.3689 - loss: 1.4961 - val_accuracy: 0.4583 - val_loss: 1.4490\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.4297 - loss: 1.4393 - val_accuracy: 0.4833 - val_loss: 1.3538\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.4574 - loss: 1.3659 - val_accuracy: 0.4667 - val_loss: 1.3076\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4738 - loss: 1.3138 - val_accuracy: 0.5167 - val_loss: 1.2651\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.5035 - loss: 1.2805 - val_accuracy: 0.5250 - val_loss: 1.2166\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.5301 - loss: 1.2257 - val_accuracy: 0.5083 - val_loss: 1.1939\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5283 - loss: 1.2326 - val_accuracy: 0.5250 - val_loss: 1.1872\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5510 - loss: 1.1516 - val_accuracy: 0.5917 - val_loss: 1.1160\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5885 - loss: 1.1287 - val_accuracy: 0.5417 - val_loss: 1.1664\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5981 - loss: 1.1006 - val_accuracy: 0.5667 - val_loss: 1.0807\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.5897 - loss: 1.0848 - val_accuracy: 0.5083 - val_loss: 1.0974\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5706 - loss: 1.1105 - val_accuracy: 0.5917 - val_loss: 1.0240\n",
      "Validation accuracy: 0.5917\n",
      "\n",
      "Training model with dropout=0.7, activation=relu, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.1656 - loss: 1.7928 - val_accuracy: 0.1667 - val_loss: 1.7898\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1864 - loss: 1.7896 - val_accuracy: 0.1667 - val_loss: 1.7849\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1782 - loss: 1.7840 - val_accuracy: 0.1750 - val_loss: 1.7764\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1884 - loss: 1.7750 - val_accuracy: 0.2667 - val_loss: 1.7640\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2701 - loss: 1.7608 - val_accuracy: 0.2750 - val_loss: 1.7376\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.2617 - loss: 1.7377 - val_accuracy: 0.3417 - val_loss: 1.7001\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3156 - loss: 1.6943 - val_accuracy: 0.3583 - val_loss: 1.6512\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3399 - loss: 1.6574 - val_accuracy: 0.3500 - val_loss: 1.6009\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3326 - loss: 1.6048 - val_accuracy: 0.3333 - val_loss: 1.5489\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3571 - loss: 1.5414 - val_accuracy: 0.3917 - val_loss: 1.4955\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3878 - loss: 1.5151 - val_accuracy: 0.3417 - val_loss: 1.5304\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3844 - loss: 1.4919 - val_accuracy: 0.3917 - val_loss: 1.4294\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3754 - loss: 1.4386 - val_accuracy: 0.4667 - val_loss: 1.3972\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4454 - loss: 1.4075 - val_accuracy: 0.4833 - val_loss: 1.3632\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4560 - loss: 1.3856 - val_accuracy: 0.4417 - val_loss: 1.3567\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4457 - loss: 1.3578 - val_accuracy: 0.4750 - val_loss: 1.3235\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4650 - loss: 1.3617 - val_accuracy: 0.4750 - val_loss: 1.3006\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4905 - loss: 1.3170 - val_accuracy: 0.4167 - val_loss: 1.3436\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4826 - loss: 1.3017 - val_accuracy: 0.5250 - val_loss: 1.2465\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5118 - loss: 1.2654 - val_accuracy: 0.5333 - val_loss: 1.2362\n",
      "Validation accuracy: 0.5333\n",
      "\n",
      "Training model with dropout=0.7, activation=relu, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.1804 - loss: 1.7985 - val_accuracy: 0.1667 - val_loss: 1.7904\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1721 - loss: 1.7928 - val_accuracy: 0.2083 - val_loss: 1.7882\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.1848 - loss: 1.7893 - val_accuracy: 0.2250 - val_loss: 1.7819\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.2434 - loss: 1.7726 - val_accuracy: 0.3167 - val_loss: 1.7145\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.2531 - loss: 1.7232 - val_accuracy: 0.2917 - val_loss: 1.6461\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.3046 - loss: 1.6341 - val_accuracy: 0.4333 - val_loss: 1.4648\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.4316 - loss: 1.4663 - val_accuracy: 0.3667 - val_loss: 1.3881\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.3960 - loss: 1.4481 - val_accuracy: 0.4500 - val_loss: 1.3055\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.4226 - loss: 1.3462 - val_accuracy: 0.4333 - val_loss: 1.2390\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.4958 - loss: 1.2731 - val_accuracy: 0.4750 - val_loss: 1.2125\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.4813 - loss: 1.2970 - val_accuracy: 0.5000 - val_loss: 1.1766\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5202 - loss: 1.1844 - val_accuracy: 0.5500 - val_loss: 1.1680\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5560 - loss: 1.1173 - val_accuracy: 0.5083 - val_loss: 1.1140\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.5717 - loss: 1.0767 - val_accuracy: 0.5417 - val_loss: 1.1108\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.5636 - loss: 1.1026 - val_accuracy: 0.4333 - val_loss: 1.2068\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.5629 - loss: 1.0403 - val_accuracy: 0.5417 - val_loss: 1.0174\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6357 - loss: 0.9671 - val_accuracy: 0.5083 - val_loss: 1.0698\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6132 - loss: 0.9826 - val_accuracy: 0.6417 - val_loss: 0.9714\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.6126 - loss: 0.9134 - val_accuracy: 0.5750 - val_loss: 0.9617\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.6029 - loss: 0.9485 - val_accuracy: 0.5833 - val_loss: 0.9954\n",
      "Validation accuracy: 0.5833\n",
      "\n",
      "Training model with dropout=0.7, activation=relu, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.1836 - loss: 1.7939 - val_accuracy: 0.1667 - val_loss: 1.7917\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.1815 - loss: 1.7917 - val_accuracy: 0.1750 - val_loss: 1.7905\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1730 - loss: 1.7907 - val_accuracy: 0.1667 - val_loss: 1.7888\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.1578 - loss: 1.7887 - val_accuracy: 0.3083 - val_loss: 1.7700\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.2352 - loss: 1.7706 - val_accuracy: 0.2833 - val_loss: 1.7082\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.2743 - loss: 1.7033 - val_accuracy: 0.2250 - val_loss: 1.7027\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2555 - loss: 1.6698 - val_accuracy: 0.3083 - val_loss: 1.5979\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3386 - loss: 1.5781 - val_accuracy: 0.3833 - val_loss: 1.4803\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.3726 - loss: 1.5012 - val_accuracy: 0.4333 - val_loss: 1.3997\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3683 - loss: 1.4452 - val_accuracy: 0.3833 - val_loss: 1.4030\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.4253 - loss: 1.3901 - val_accuracy: 0.4167 - val_loss: 1.3087\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.4645 - loss: 1.3472 - val_accuracy: 0.4000 - val_loss: 1.3449\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4232 - loss: 1.3657 - val_accuracy: 0.4417 - val_loss: 1.2629\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4515 - loss: 1.3216 - val_accuracy: 0.4333 - val_loss: 1.3428\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4409 - loss: 1.3344 - val_accuracy: 0.4083 - val_loss: 1.3220\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3994 - loss: 1.3945 - val_accuracy: 0.4333 - val_loss: 1.2319\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4503 - loss: 1.2800 - val_accuracy: 0.4750 - val_loss: 1.2339\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5019 - loss: 1.2349 - val_accuracy: 0.3833 - val_loss: 1.3818\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4249 - loss: 1.3663 - val_accuracy: 0.5167 - val_loss: 1.1982\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4814 - loss: 1.2264 - val_accuracy: 0.4750 - val_loss: 1.2196\n",
      "Validation accuracy: 0.4750\n",
      "\n",
      "Training model with dropout=0.7, activation=sigmoid, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.1410 - loss: 1.9019 - val_accuracy: 0.1667 - val_loss: 1.8210\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1629 - loss: 1.8286 - val_accuracy: 0.1667 - val_loss: 1.8210\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.1398 - loss: 1.8282 - val_accuracy: 0.1667 - val_loss: 1.8199\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.1892 - loss: 1.7986 - val_accuracy: 0.1667 - val_loss: 1.8841\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.1839 - loss: 1.8493 - val_accuracy: 0.1667 - val_loss: 1.8340\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1653 - loss: 1.8167 - val_accuracy: 0.1833 - val_loss: 1.8033\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1945 - loss: 1.7891 - val_accuracy: 0.1667 - val_loss: 1.7825\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2040 - loss: 1.7920 - val_accuracy: 0.2000 - val_loss: 1.7676\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.1762 - loss: 1.7742 - val_accuracy: 0.3250 - val_loss: 1.7742\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.2169 - loss: 1.7671 - val_accuracy: 0.2833 - val_loss: 1.7329\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2390 - loss: 1.7504 - val_accuracy: 0.3000 - val_loss: 1.7191\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.2695 - loss: 1.7324 - val_accuracy: 0.3000 - val_loss: 1.7108\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.2878 - loss: 1.7156 - val_accuracy: 0.3500 - val_loss: 1.6633\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.3118 - loss: 1.6740 - val_accuracy: 0.2917 - val_loss: 1.6629\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.3238 - loss: 1.6441 - val_accuracy: 0.3167 - val_loss: 1.6003\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.3882 - loss: 1.5889 - val_accuracy: 0.4583 - val_loss: 1.5544\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3709 - loss: 1.5756 - val_accuracy: 0.3250 - val_loss: 1.5669\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.3331 - loss: 1.6033 - val_accuracy: 0.2750 - val_loss: 1.6318\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.3684 - loss: 1.5504 - val_accuracy: 0.4000 - val_loss: 1.4648\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4322 - loss: 1.4482 - val_accuracy: 0.4750 - val_loss: 1.4132\n",
      "Validation accuracy: 0.4750\n",
      "\n",
      "Training model with dropout=0.7, activation=sigmoid, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.1542 - loss: 1.9943 - val_accuracy: 0.1667 - val_loss: 1.7947\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.1786 - loss: 1.8141 - val_accuracy: 0.1667 - val_loss: 1.7908\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.1823 - loss: 1.7939 - val_accuracy: 0.1667 - val_loss: 1.7879\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.1719 - loss: 1.7924 - val_accuracy: 0.1667 - val_loss: 1.8275\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1657 - loss: 1.8220 - val_accuracy: 0.1667 - val_loss: 1.8096\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.1972 - loss: 1.7835 - val_accuracy: 0.1667 - val_loss: 1.7907\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.2196 - loss: 1.7880 - val_accuracy: 0.1667 - val_loss: 1.7835\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.1914 - loss: 1.7832 - val_accuracy: 0.1667 - val_loss: 1.7775\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.1884 - loss: 1.7874 - val_accuracy: 0.1667 - val_loss: 1.7711\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.1756 - loss: 1.7786 - val_accuracy: 0.2417 - val_loss: 1.7637\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2613 - loss: 1.7585 - val_accuracy: 0.2333 - val_loss: 1.7607\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2461 - loss: 1.7542 - val_accuracy: 0.2667 - val_loss: 1.7533\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.2159 - loss: 1.7604 - val_accuracy: 0.2333 - val_loss: 1.7406\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.2677 - loss: 1.7478 - val_accuracy: 0.3167 - val_loss: 1.7227\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2701 - loss: 1.7296 - val_accuracy: 0.3083 - val_loss: 1.7064\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.3129 - loss: 1.7000 - val_accuracy: 0.3500 - val_loss: 1.7034\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2719 - loss: 1.6955 - val_accuracy: 0.2750 - val_loss: 1.6564\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.3510 - loss: 1.6654 - val_accuracy: 0.4750 - val_loss: 1.6143\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.4034 - loss: 1.6315 - val_accuracy: 0.3083 - val_loss: 1.6073\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.3385 - loss: 1.6267 - val_accuracy: 0.3250 - val_loss: 1.5800\n",
      "Validation accuracy: 0.3250\n",
      "\n",
      "Training model with dropout=0.7, activation=sigmoid, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.1678 - loss: 1.8295 - val_accuracy: 0.1667 - val_loss: 1.7939\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1582 - loss: 1.7968 - val_accuracy: 0.1667 - val_loss: 1.7935\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1823 - loss: 1.7973 - val_accuracy: 0.1667 - val_loss: 1.7860\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1832 - loss: 1.7882 - val_accuracy: 0.1667 - val_loss: 1.7879\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2001 - loss: 1.7856 - val_accuracy: 0.4083 - val_loss: 1.7818\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.2242 - loss: 1.7843 - val_accuracy: 0.1667 - val_loss: 1.7806\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1797 - loss: 1.7827 - val_accuracy: 0.1667 - val_loss: 1.7914\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1936 - loss: 1.7937 - val_accuracy: 0.2333 - val_loss: 1.7713\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2424 - loss: 1.7726 - val_accuracy: 0.1750 - val_loss: 1.7658\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.1919 - loss: 1.7736 - val_accuracy: 0.1667 - val_loss: 1.7605\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2239 - loss: 1.7661 - val_accuracy: 0.2000 - val_loss: 1.7583\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1967 - loss: 1.7623 - val_accuracy: 0.1667 - val_loss: 1.7600\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2256 - loss: 1.7551 - val_accuracy: 0.2333 - val_loss: 1.7385\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2962 - loss: 1.7464 - val_accuracy: 0.2583 - val_loss: 1.7430\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2782 - loss: 1.7280 - val_accuracy: 0.1750 - val_loss: 1.7301\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2285 - loss: 1.7264 - val_accuracy: 0.3667 - val_loss: 1.7021\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3086 - loss: 1.7109 - val_accuracy: 0.2583 - val_loss: 1.6932\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2956 - loss: 1.7049 - val_accuracy: 0.3083 - val_loss: 1.6753\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3543 - loss: 1.6821 - val_accuracy: 0.3417 - val_loss: 1.6588\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3605 - loss: 1.6718 - val_accuracy: 0.3583 - val_loss: 1.6279\n",
      "Validation accuracy: 0.3583\n",
      "\n",
      "Training model with dropout=0.7, activation=sigmoid, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.1751 - loss: 1.8582 - val_accuracy: 0.1667 - val_loss: 1.8118\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.1674 - loss: 1.8124 - val_accuracy: 0.1667 - val_loss: 1.8112\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.1476 - loss: 1.8094 - val_accuracy: 0.1667 - val_loss: 1.8024\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.1642 - loss: 1.8096 - val_accuracy: 0.1667 - val_loss: 1.8096\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1714 - loss: 1.8021 - val_accuracy: 0.1667 - val_loss: 1.8193\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1716 - loss: 1.8070 - val_accuracy: 0.1667 - val_loss: 1.8086\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.1480 - loss: 1.8125 - val_accuracy: 0.1667 - val_loss: 1.8022\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1576 - loss: 1.8105 - val_accuracy: 0.1667 - val_loss: 1.8019\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.1890 - loss: 1.8002 - val_accuracy: 0.1667 - val_loss: 1.8007\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.1501 - loss: 1.8033 - val_accuracy: 0.1667 - val_loss: 1.7950\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1807 - loss: 1.7981 - val_accuracy: 0.1667 - val_loss: 1.7908\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.1881 - loss: 1.7965 - val_accuracy: 0.1667 - val_loss: 1.8064\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.1634 - loss: 1.8049 - val_accuracy: 0.1667 - val_loss: 1.7886\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.2043 - loss: 1.7904 - val_accuracy: 0.1667 - val_loss: 1.7960\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.1907 - loss: 1.7963 - val_accuracy: 0.2167 - val_loss: 1.7917\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2118 - loss: 1.7879 - val_accuracy: 0.1750 - val_loss: 1.7970\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.1823 - loss: 1.7944 - val_accuracy: 0.2167 - val_loss: 1.7817\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.1847 - loss: 1.7862 - val_accuracy: 0.1667 - val_loss: 1.7915\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.1670 - loss: 1.7943 - val_accuracy: 0.3167 - val_loss: 1.7513\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.2472 - loss: 1.7504 - val_accuracy: 0.3417 - val_loss: 1.7099\n",
      "Validation accuracy: 0.3417\n",
      "\n",
      "Training model with dropout=0.7, activation=sigmoid, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.1563 - loss: 1.8349 - val_accuracy: 0.1667 - val_loss: 1.8114\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1618 - loss: 1.8170 - val_accuracy: 0.1667 - val_loss: 1.8260\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1617 - loss: 1.8108 - val_accuracy: 0.1667 - val_loss: 1.8134\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1600 - loss: 1.8133 - val_accuracy: 0.1667 - val_loss: 1.8026\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1818 - loss: 1.8009 - val_accuracy: 0.1667 - val_loss: 1.8030\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1479 - loss: 1.8109 - val_accuracy: 0.1667 - val_loss: 1.8091\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1679 - loss: 1.8134 - val_accuracy: 0.1667 - val_loss: 1.8026\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1483 - loss: 1.7996 - val_accuracy: 0.1667 - val_loss: 1.8082\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1423 - loss: 1.8184 - val_accuracy: 0.1667 - val_loss: 1.8031\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1683 - loss: 1.8031 - val_accuracy: 0.1667 - val_loss: 1.7940\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1805 - loss: 1.7976 - val_accuracy: 0.1667 - val_loss: 1.7909\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1750 - loss: 1.7965 - val_accuracy: 0.2583 - val_loss: 1.8039\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2054 - loss: 1.7943 - val_accuracy: 0.1667 - val_loss: 1.7912\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1617 - loss: 1.7968 - val_accuracy: 0.1667 - val_loss: 1.7930\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1736 - loss: 1.7911 - val_accuracy: 0.1667 - val_loss: 1.8034\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1703 - loss: 1.7901 - val_accuracy: 0.2000 - val_loss: 1.7779\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1905 - loss: 1.7887 - val_accuracy: 0.1667 - val_loss: 1.7862\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1859 - loss: 1.7797 - val_accuracy: 0.1667 - val_loss: 1.7633\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2122 - loss: 1.7625 - val_accuracy: 0.1750 - val_loss: 1.7569\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2304 - loss: 1.7558 - val_accuracy: 0.3500 - val_loss: 1.7237\n",
      "Validation accuracy: 0.3500\n",
      "\n",
      "Training model with dropout=0.7, activation=tanh, hidden_units=[512, 256]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.1845 - loss: 1.8240 - val_accuracy: 0.1667 - val_loss: 1.7616\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.2493 - loss: 1.7158 - val_accuracy: 0.2500 - val_loss: 1.6177\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.3387 - loss: 1.5798 - val_accuracy: 0.4083 - val_loss: 1.3609\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.3943 - loss: 1.4383 - val_accuracy: 0.4083 - val_loss: 1.3701\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.4874 - loss: 1.3050 - val_accuracy: 0.4917 - val_loss: 1.1750\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5183 - loss: 1.1387 - val_accuracy: 0.5583 - val_loss: 1.0703\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.5511 - loss: 1.1259 - val_accuracy: 0.6500 - val_loss: 1.0519\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6220 - loss: 1.0187 - val_accuracy: 0.5500 - val_loss: 1.0794\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5255 - loss: 1.2019 - val_accuracy: 0.5833 - val_loss: 1.0442\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6261 - loss: 0.9508 - val_accuracy: 0.5833 - val_loss: 0.9342\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6707 - loss: 0.8872 - val_accuracy: 0.6750 - val_loss: 0.8865\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6861 - loss: 0.8688 - val_accuracy: 0.6000 - val_loss: 1.0178\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.6326 - loss: 0.9469 - val_accuracy: 0.5417 - val_loss: 1.1638\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.6369 - loss: 0.9099 - val_accuracy: 0.5667 - val_loss: 0.9190\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6800 - loss: 0.7995 - val_accuracy: 0.7000 - val_loss: 0.7876\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7570 - loss: 0.7053 - val_accuracy: 0.6833 - val_loss: 0.8672\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.7076 - loss: 0.7545 - val_accuracy: 0.6500 - val_loss: 0.9328\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6779 - loss: 0.8723 - val_accuracy: 0.6750 - val_loss: 0.9576\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.7173 - loss: 0.7871 - val_accuracy: 0.7417 - val_loss: 0.7415\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.7760 - loss: 0.6298 - val_accuracy: 0.7250 - val_loss: 0.7216\n",
      "Validation accuracy: 0.7250\n",
      "\n",
      "Training model with dropout=0.7, activation=tanh, hidden_units=[256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.1729 - loss: 1.8171 - val_accuracy: 0.1667 - val_loss: 1.7794\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2172 - loss: 1.7673 - val_accuracy: 0.2667 - val_loss: 1.6678\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.2729 - loss: 1.6582 - val_accuracy: 0.5167 - val_loss: 1.4727\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.4198 - loss: 1.4595 - val_accuracy: 0.5083 - val_loss: 1.3157\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.4891 - loss: 1.2616 - val_accuracy: 0.4667 - val_loss: 1.1458\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.5150 - loss: 1.1701 - val_accuracy: 0.5583 - val_loss: 1.2072\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5485 - loss: 1.1716 - val_accuracy: 0.5667 - val_loss: 1.1718\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.5510 - loss: 1.1104 - val_accuracy: 0.6000 - val_loss: 1.0058\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6718 - loss: 0.9399 - val_accuracy: 0.6000 - val_loss: 1.0559\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6138 - loss: 1.0151 - val_accuracy: 0.5500 - val_loss: 1.1236\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.5764 - loss: 1.0737 - val_accuracy: 0.6250 - val_loss: 0.9261\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6572 - loss: 0.9311 - val_accuracy: 0.6167 - val_loss: 0.9201\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.6489 - loss: 0.9007 - val_accuracy: 0.6333 - val_loss: 0.8984\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7089 - loss: 0.8420 - val_accuracy: 0.6667 - val_loss: 0.9206\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.6880 - loss: 0.8229 - val_accuracy: 0.6417 - val_loss: 0.8798\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7515 - loss: 0.7402 - val_accuracy: 0.6750 - val_loss: 0.8041\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7527 - loss: 0.6997 - val_accuracy: 0.7083 - val_loss: 0.7458\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.7731 - loss: 0.6661 - val_accuracy: 0.7083 - val_loss: 0.7847\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7439 - loss: 0.6721 - val_accuracy: 0.7500 - val_loss: 0.7352\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7726 - loss: 0.6811 - val_accuracy: 0.5917 - val_loss: 0.9494\n",
      "Validation accuracy: 0.5917\n",
      "\n",
      "Training model with dropout=0.7, activation=tanh, hidden_units=[128, 64]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.1929 - loss: 1.8018 - val_accuracy: 0.1667 - val_loss: 1.7610\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2159 - loss: 1.7656 - val_accuracy: 0.4083 - val_loss: 1.6879\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3689 - loss: 1.6775 - val_accuracy: 0.4000 - val_loss: 1.5664\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3947 - loss: 1.5443 - val_accuracy: 0.3083 - val_loss: 1.5628\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3755 - loss: 1.4984 - val_accuracy: 0.3833 - val_loss: 1.3670\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4819 - loss: 1.3104 - val_accuracy: 0.5500 - val_loss: 1.2440\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5442 - loss: 1.2299 - val_accuracy: 0.4500 - val_loss: 1.2117\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5205 - loss: 1.1556 - val_accuracy: 0.5167 - val_loss: 1.1331\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6045 - loss: 1.0705 - val_accuracy: 0.5500 - val_loss: 1.0360\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6151 - loss: 1.0400 - val_accuracy: 0.5833 - val_loss: 0.9984\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6050 - loss: 0.9980 - val_accuracy: 0.5833 - val_loss: 1.0019\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6370 - loss: 0.9367 - val_accuracy: 0.5500 - val_loss: 1.0033\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6029 - loss: 0.9605 - val_accuracy: 0.5167 - val_loss: 1.0031\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6550 - loss: 0.9034 - val_accuracy: 0.6333 - val_loss: 0.8907\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6650 - loss: 0.8716 - val_accuracy: 0.6000 - val_loss: 0.8873\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6803 - loss: 0.8196 - val_accuracy: 0.5750 - val_loss: 0.9403\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6592 - loss: 0.8732 - val_accuracy: 0.4667 - val_loss: 1.2508\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6236 - loss: 0.9990 - val_accuracy: 0.6750 - val_loss: 0.8276\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7053 - loss: 0.8145 - val_accuracy: 0.6250 - val_loss: 0.9356\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6665 - loss: 0.8729 - val_accuracy: 0.7000 - val_loss: 0.8661\n",
      "Validation accuracy: 0.7000\n",
      "\n",
      "Training model with dropout=0.7, activation=tanh, hidden_units=[512, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.1542 - loss: 1.8240 - val_accuracy: 0.2833 - val_loss: 1.7279\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.2855 - loss: 1.7010 - val_accuracy: 0.2917 - val_loss: 1.5720\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.3551 - loss: 1.5453 - val_accuracy: 0.5000 - val_loss: 1.2820\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5038 - loss: 1.2947 - val_accuracy: 0.5167 - val_loss: 1.2049\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.4922 - loss: 1.2397 - val_accuracy: 0.5250 - val_loss: 1.3403\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.5187 - loss: 1.1950 - val_accuracy: 0.5250 - val_loss: 1.0988\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5882 - loss: 1.0472 - val_accuracy: 0.5000 - val_loss: 1.1550\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.5537 - loss: 1.0753 - val_accuracy: 0.6500 - val_loss: 1.0311\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6621 - loss: 0.9523 - val_accuracy: 0.6500 - val_loss: 0.9785\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6762 - loss: 0.8862 - val_accuracy: 0.5917 - val_loss: 1.0383\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6834 - loss: 0.8635 - val_accuracy: 0.5250 - val_loss: 1.0744\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6079 - loss: 1.0048 - val_accuracy: 0.6750 - val_loss: 0.8599\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.6904 - loss: 0.8309 - val_accuracy: 0.5333 - val_loss: 1.0050\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6222 - loss: 0.9621 - val_accuracy: 0.6083 - val_loss: 0.9616\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6599 - loss: 0.9478 - val_accuracy: 0.6083 - val_loss: 0.9716\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6832 - loss: 0.8228 - val_accuracy: 0.6417 - val_loss: 0.8478\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.7150 - loss: 0.7349 - val_accuracy: 0.6750 - val_loss: 0.8264\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.7333 - loss: 0.7447 - val_accuracy: 0.6833 - val_loss: 0.7463\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.7375 - loss: 0.6818 - val_accuracy: 0.6917 - val_loss: 0.7247\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.7494 - loss: 0.6830 - val_accuracy: 0.6167 - val_loss: 0.8089\n",
      "Validation accuracy: 0.6167\n",
      "\n",
      "Training model with dropout=0.7, activation=tanh, hidden_units=[128, 256, 128]\n",
      "Epoch 1/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.1841 - loss: 1.7999 - val_accuracy: 0.1667 - val_loss: 1.7885\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2187 - loss: 1.7585 - val_accuracy: 0.2833 - val_loss: 1.6481\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.2824 - loss: 1.6530 - val_accuracy: 0.3917 - val_loss: 1.4572\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4138 - loss: 1.4226 - val_accuracy: 0.3833 - val_loss: 1.4066\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4087 - loss: 1.3856 - val_accuracy: 0.4833 - val_loss: 1.2221\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4794 - loss: 1.2049 - val_accuracy: 0.4417 - val_loss: 1.1564\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5484 - loss: 1.1402 - val_accuracy: 0.5417 - val_loss: 1.0758\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5594 - loss: 1.0933 - val_accuracy: 0.5667 - val_loss: 1.0522\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5779 - loss: 1.0726 - val_accuracy: 0.5500 - val_loss: 1.0475\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5709 - loss: 1.0526 - val_accuracy: 0.5167 - val_loss: 1.3034\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6113 - loss: 0.9834 - val_accuracy: 0.5083 - val_loss: 1.2876\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6080 - loss: 0.9842 - val_accuracy: 0.5833 - val_loss: 1.0745\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6308 - loss: 0.9221 - val_accuracy: 0.6667 - val_loss: 0.8341\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7100 - loss: 0.7955 - val_accuracy: 0.6917 - val_loss: 0.7992\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7014 - loss: 0.8017 - val_accuracy: 0.6750 - val_loss: 0.8744\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7159 - loss: 0.7523 - val_accuracy: 0.6250 - val_loss: 0.9567\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7097 - loss: 0.7675 - val_accuracy: 0.6417 - val_loss: 0.8063\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7369 - loss: 0.7109 - val_accuracy: 0.5667 - val_loss: 0.9954\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6906 - loss: 0.7662 - val_accuracy: 0.6583 - val_loss: 0.7681\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7853 - loss: 0.6182 - val_accuracy: 0.6917 - val_loss: 0.7786\n",
      "Validation accuracy: 0.6917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for dropout, activation, hidden_units in itertools.product(dropouts, activations, hidden_units_list):\n",
    "    with tf.device(device):\n",
    "        print(f\"Training model with dropout={dropout}, activation={activation}, hidden_units={hidden_units}\")\n",
    "        \n",
    "        model = MyModel(activation=activation, dropout_rate=dropout, hidden_units=hidden_units, num_classes=6)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, Y_train_one_hot,\n",
    "            validation_data=(X_test, Y_test_one_hot),\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        val_acc = history.history['val_accuracy'][-1]\n",
    "        print(f\"Validation accuracy: {val_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b46c1",
   "metadata": {},
   "source": [
    "Activation Functions:\n",
    "`tanh` consistently outperformed others, especially with higher dropout rates — delivering stable and strong accuracy. `ReLU` performed decently but didn't stand out, while `sigmoid` was generally disappointing, rarely exceeding 45%.\n",
    "\n",
    "Network Depth:\n",
    "More layers didn’t necessarily lead to better performance. In many cases, two-layer networks outperformed three-layer ones. For example, with `tanh` and `dropout=0.1`, the [128, 64] model achieved 70%, while a deeper [128, 256, 128] setup only reached 65.83%. It seems the task isn't complex enough to require deep architectures.\n",
    "\n",
    "Layer Size:\n",
    "Compact models like [128, 64] often performed as well as larger ones like [512, 256], suggesting the dataset doesn’t benefit significantly from high-capacity networks.\n",
    "\n",
    "The best config is - dropout=0.5, activation=tanh, hidden_units=[512, 256] with accuracy 0.8167"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
